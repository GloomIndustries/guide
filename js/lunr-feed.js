var index = lunr(function () {
  this.field('title')
  this.field('content', {boost: 10})
  this.ref('id')
});

index.add({
title: null,
content: "\n    \n        404\n        Page not found\n    \n\n",
id: 0
});

index.add({
title: "FAQ",
content: "Frequently Asked Questions\n\nHow do I skip a build?\n\nYou might want to skip a build if you’re only changing documentation.\n\nIf you don’t want Screwdriver to trigger a build when you’re pushing to master, add [ci skip] or [skip ci] somewhere in the commit message. If you don’t want Screwdriver to trigger a build when you merge a pull request, add [ci skip] or [skip ci] to the pull request title.\n\nNote: Doesn’t apply to pull request builds: a commit message containing [skip ci] or [ci skip] will still trigger a pre-commit job (a PR job will always run).\n\nHow do I create a pipeline?\n\nTo create a pipeline, click the Create icon and paste a Git URL into the form. Followed by # and the branch name, if the branch is not master.\n\n\n\nHow do I start a pipeline manually?\n\nTo start a build manually, click the Start button on your pipeline page.\n\n\n\nHow do I update a pipeline repo and branch?\n\nIf you want to update your pipeline repo and branch, modify the checkout URL in the Options tab on your pipeline page and click Update.\n\n\n\nHow do I disable/enable a job temporarily?\n\nTo temporarily disable/enable a job to quickly stop the line, toggle the switch to disable/enable for a particular job under the Options tab on your pipeline page.\n\n\n\nHow do I make sure my code is in sync with my pipeline?\n\nIf your pipeline looks out of sync after changes were made to it, to make sure it’s in sync with your source code. On the Options tab in your pipeline page, click the Sync icon to update the out of sync elements. There are separate Sync icons for SCM webhooks, pull request builds, and pipeline jobs.\n\n\n\nHow do I delete a pipeline permanently?\n\nIndividual pipelines may be removed by clicking the Delete icon on the Options tab in your pipeline page. This action is not undoable.\n\n\n",
id: 1
});

index.add({
title: "FAQ",
content: "Frequently Asked Questions\n\nHow do I create a pipeline?\n\nTo create a pipeline, click the Create icon and paste a Git URL into the form. Followed by # and the branch name, if the branch is not master.\n\n\n\nHow do I start a pipeline manually?\n\nTo start a build manually, click the Start button on your pipeline page.\n\n\n\nHow do I update a pipeline repo and branch?\n\nIf you want to update your pipeline repo and branch, modify the checkout URL in the Options tab on your pipeline page and click Update.\n\n\n\nHow do I disable/enable a job temporarily?\n\nTo temporarily disable/enable a job to quickly stop the line, toggle the switch to disable/enable for a particular job under the Options tab on your pipeline page.\n\n\n\nHow do I make sure my code is in sync with my pipeline?\n\nIf your pipeline looks out of sync after changes were made to it, to make sure it’s in sync with your source code. On the Options tab in your pipeline page, click the Sync icon to update the out of sync elements. There are separate Sync icons for SCM webhooks, pull request builds, and pipeline jobs.\n\n\n\nHow do I delete a pipeline permanently?\n\nIndividual pipelines may be removed by clicking the Delete icon on the Options tab in your pipeline page. This action is not undoable.\n\n\n",
id: 2
});

index.add({
title: "API",
content: "API\n\nScrewdriver APIs and the data models around them are documented via Swagger. This prevents out-of-date documentation, enables clients to be auto-generated, and most importantly exposes a human-readable interface.\n\n\n  Version 4 is the current API, all links should be prefixed with /v4.\n\n\nOur API documentation can be found at api.screwdriver.cd/v4/documentation. To see yours, go to /v4/documentation.\n\nUsing the API\nWith Swagger\nSwagger documentation includes examples and editable parameters to play around with. Visit the /v4/documentation page and use the interactive Try it out! buttons to make calls to our API.\n\nSwagger page:\n\n\nResponse:\n\n\nWith a REST Client\nUse a REST client like Postman to make requests against the API. You will need an authorization token. To get an authorization token, login using /v4/auth/login and copy the token value when redirected to /v4/auth/token. See the Authorization and Authentication section for more information.\n\nRequests can be made to the API with headers like below:\nContent-Type: application/json\nAuthorization: Bearer &lt;YOUR_TOKEN_HERE&gt;\n\n\n\nExample request:\n\n\nFor more information and examples, check out our API documentation.\n\nAuthentication and Authorization\n\nFor Authentication we’re using JSON Web Tokens (JWTs) and Screwdriver API Tokens. JWTs need to be passed via\nan Authorization header.\n\n  To generate a JWT with OAuth, visit the /v4/auth/login endpoint, which will redirect you to the /v4/auth/token endpoint.\n  To generate a JWT with a Screwdriver API Token, make a GET request to the /v4/auth/token endpoint with your API token as the api_token query parameter.\n\n\nScrewdriver API tokens can be managed from Screwdriver’s user settings page.\n\nAuthorization is handled by your SCM. Screwdriver uses SCM user tokens\nand identity to:\n\n\n  identify what repositories you have read, write, and admin access to\n    \n      read allows you to view the pipeline\n      write allows you to start or stop jobs\n      admin allows you to create, edit, or delete pipelines\n    \n  \n  read the repository’s screwdriver.yaml\n  enumerate the list of pull-requests open on your repository\n  update the pull-request with the success/failure of the build\n  add/remove repository web-hooks so Screwdriver can be notified on changes\n\n\nFor more information, see the GitHub OAuth documentation.\n\nBadges\n\nTo get an image that displays the current build statuses for a particular pipeline, you can use the URL &lt;your_UI_URL&gt;/pipelines/&lt;your_pipelineId&gt;/badge.\n\n\n\nFor example, we display the badge above by using this code in Markdown. The status-image URL gives you the badge image and the status-url should be the link to your pipeline.\n\n[![Build Status][status-image]][status-url]\n\n[status-image]: https://cd.screwdriver.cd/pipelines/1/badge\n[status-url]: https://cd.screwdriver.cd/pipelines/1\n\n\n\nDesign\n\nOur API was designed with three principles in mind:\n\n\n  All interactions of user’s data should be done through the API, so that\nthere is a consistent interface across the tools (CLI, Web UI, etc.).\n  Resources should be REST-ful and operations should be atomic so that intent\nis clear and human readable.\n  API should be versioned and self-documented, so that client code generation\nis possible.\n\n\nMake Your Own\nIf you’d like to make your own Swagger documentation, check out our JSON for reference at  https://api.screwdriver.cd/v4/swagger.json. To see your Swagger.json, visit /v4/swagger.json.\n\n",
id: 3
});

index.add({
title: "API",
content: "API\n\nScrewdriverのAPIとデータモデルはSwaggerを使ってドキュメント化されています。ドキュメントが古くなることを防ぐため、自動生成され、人が読みやすいインタフェースになっています。\n\n\n  現在のAPIはVersion 4で、全てのAPIは/v4で始まります。\n\n\nAPIのドキュメントは以下で見ることができます api.screwdriver.cd/v4/documentation ご自身のScrewdriverで見るためには、/v4/documentationにアクセスしてください。\n\nAPIを使用する\n\nSwagger経由で使用する\n\nSwaggerのドキュメントは例とお試しのための編集可能なパラメータを含んでいます。/v4/documentationにアクセスし、APIを呼び出すためのTry it out!ボタンをお試しください。\n\nSwagger page:\n\n\nResponse:\n\n\nRESTクライアント経由で実行する\n\nPostmanのようなRESTクライアントをAPIリクエストに使用します。その際、認証トークンが必要です。認証トークンを取得するためには、/v4/auth/loginからログインし、リダイレクト先の/v4/auth/token/v4/auth/tokenからトークンをコピーしてください。詳しくは認可と認証をご覧ください。\n\nAPIリクエストの際のヘッダは以下のようになります。\n\nContent-Type: application/json\nAuthorization: Bearer &lt;YOUR_TOKEN_HERE&gt;\n\n\n\nExample request:\n\n\n詳しい情報と例についてはAPIドキュメントをご覧ください。\n\n認可と認証\n\n認証のために、JSON Web Tokens (JWT)を使用しています。JWTは\nAuthorizationヘッダを必要とします。JWTを生成するために/v4/auth/login にアクセスし、/v4/auth/tokenへとリダイレクトされます。\n\n一方、認可はOAuthによるものです。/v4/auth/loginにアクセスしたときに行われます。ScrewdriverはSCMトークンで以下を識別します。\n\n\n  レポジトリへのread, write, adminアクセスを識別します。\n    \n      read権限でpipelineを見ることができます。\n      write権限でjobの開始と停止ができます。\n      admin権限でpipelineの作成、編集、削除ができます。\n    \n  \n  リポジトリのscrewdriver.yamlの読み込み\n  ビルドの成功・失敗情報でpull-requestを更新\n  ビルドの成功・失敗情報でpull-requestを更新\n  Screwdriverが変更の通知を受け取れるよう、リポジトリに対しwebhookを追加・削除\n\n\nより詳しい情報についてはGitHub OAuthのドキュメントをご覧ください。\n\n設計思想\n\nScrewdriverのAPIは次の三原則を念頭に設計されました。\n\n\n  CLIやWebUIなど各ツールで一貫したインターフェースとするため、全てのユーザーデータへの操作をAPI経由にすべき\n  意図がわかりやすく、人間が読みやすくするため、リソースはREST-fulであるべきで、操作は小さく区切るべき\n  クライアントのコード自動生成を可能にするため、APIにはバージョンがあり自己文書化されているべき\n\n\nMake Your Own\n\nあなた自身の Swaggerドキュメントを作成するには、以下のJSONリファレンスを確認して下さい https://api.screwdriver.cd/v4/swagger.jsonご自身のSwagger.jsonを見るためには、/v4/swagger.jsonにアクセスしてください。\n",
id: 4
});

index.add({
title: "Authentication and Authorization",
content: "Access Control\n\nTo simplify access, Screwdriver uses the same security model as the Pipeline’s Git repository.\n\nAuthorization\n\nFor this example, we will be using the GitHub SCM provider.\n\nDepending on your permission level to a Git repository, you will have corresponding access to the linked Screwdriver Pipeline.\n\n\n  Read (Guest)\n    \n      View the overall status of the pipeline\n      View the log of a build\n    \n  \n  Write (Collaborator)\n    \n      All permissions as a Guest\n      Start a new build\n      Stop an existing build\n    \n  \n  Admin (Owner)\n    \n      All permissions as a Collaborator\n      Create a new pipeline for this repository\n      Delete the existing pipeline\n      Create, update, delete secrets\n      Disable and enable jobs\n    \n  \n\n\nAuthentication\n\nFor Screwdriver to determine your permission level, you need to complete a one-time procedure to link your Git accounts to Screwdriver.  This will only give Screwdriver limited access to your repositories:\n\n\n  READ-ONLY access to public repositories - To read the contents of screwdriver.yaml files.\n  Full control of repository hooks - To add/remove Screwdriver webhook on pipeline creation/deletion.\n  Read org and team membership - To determine your permission-level (see above).\n  Access commit status - To update Pull Requests with the success or failure of your builds.\n\n",
id: 5
});

index.add({
title: "認可と認証",
content: "アクセス制御\n\nアクセスをシンプルにするため、ScrewdriverはパイプラインのGitリポジトリと同じセキュリティモデルを採用しています。\n\n認可\n\nこの例ではGitHub SCMプロバイダを使用します\n\nGitリポジトリ上の各自のパーミッションレベルに応じて、リンクされているScrewdriverパイプラインへのアクセス権が設定されます。\n\n\n  読み取り(ゲスト)\n    \n      パイプライン全体の状態を表示\n      ビルドログの表示\n    \n  \n  書き込み(コラボレーター)\n    \n      ゲストが可能な操作\n      新しくビルドを開始\n      既存のビルドを停止\n    \n  \n  管理(所有者)\n    \n      コラボレーターが可能な操作\n      該当リポジトリのパイプラインの作成\n      既存のパイプラインの削除\n      secretsの作成、更新、削除\n      ジョブの有効化と無効化\n    \n  \n\n\n認証\n\nScrewdriverが利用者のパーミッションレベルを決定するため、初回だけScrewdriverにGitアカウントをリンクする手続きを行う必要があります。これにより、Screwdriverには次の通り制限されたアクセス権が付与されます。\n\n\n  公開リポジトリへの読み取り専用アクセス - screwdriver.yamlの中身を読み込むため\n  リポジトリのwebhookの完全制御 - パイプラインの作成・削除に合わせてScrewdriverのwebhookの追加・削除を行うため\n  orgとチームメンバーシップの読み取り - 利用者のパーミッションレベルの確認（上記参照）\n  コミットステータスへのアクセス - ビルドの成功・失敗情報でPull Requestを更新するため\n\n",
id: 6
});

index.add({
title: "Configuring the API",
content: "Managing the API\n\nPackages\n\nLike the other services, the API is shipped as a Docker image with port 8080 exposed.\n\n$ docker run -d -p 9000:8080 screwdrivercd/screwdriver:stable\n$ open http://localhost:9000\n\n\n\nOur images are tagged for their version (eg. 1.2.3) as well as a floating latest and stable.  Most installations should be using stable or the fixed version tags.\n\nConfiguration\nScrewdriver already defaults most configuration, but you can override defaults using a config/local.yaml or environment variables. All the possible environment variables are defined here.\n\nAuthentication / Authorization\n\nConfigure how users can and who can access the API.\n\n\n  \n    \n      Key\n      Required\n      Description\n    \n  \n  \n    \n      SECRET_JWT_PRIVATE_KEY\n      Yes\n      A private key uses for signing jwt tokens. Generate one by running $ openssl genrsa -out jwt.pem 2048\n    \n    \n      SECRET_JWT_PUBLIC_KEY\n      Yes\n      The public key used for verifying the signature. Generate one by running $ openssl rsa -in jwt.pem -pubout -out jwt.pub\n    \n    \n      SECRET_COOKIE_PASSWORD\n      Yes\n      A password used for encrypting session data. Needs to be minimum 32 characters\n    \n    \n      SECRET_PASSWORD\n      Yes\n      A password used for encrypting stored secrets. Needs to be minimum 32 characters\n    \n    \n      IS_HTTPS\n      No\n      A flag to set if the server is running over https. Used as a flag for the OAuth flow (default to false)\n    \n    \n      SECRET_WHITELIST\n      No\n      Whitelist of users able to authenticate against the system. If empty, it allows everyone. (JSON Array format)\n    \n    \n      SECRET_ADMINS\n      No\n      Whitelist of users able to authenticate against the system. If empty, it allows everyone. (JSON Array format)\n    \n  \n\n\n# config/local.yaml\nauth:\n    jwtPrivateKey: |\n        PRIVATE KEY HERE\n    jwtPublicKey: |\n        PUBLIC KEY HERE\n    cookiePassword: 975452d6554228b581bf34197bcb4e0a08622e24\n    encryptionPassword: 5c6d9edc3a951cda763f650235cfc41a3fc23fe8\n    https: false\n    whitelist:\n        - github:batman\n        - github:robin\n    admins:\n        - github:batman\n\n\n\nBookend Plugins\n\nYou can globally configure which built-in bookend plugins will be used during a build. By default, scm is enabled to begin builds with a SCM checkout command.\n\nIf you’re looking to include a custom bookend in the API, please refer here.\n\n\n  \n    \n      Key\n      Default\n      Description\n    \n  \n  \n    \n      BOOKENDS_SETUP\n      None\n      The ordered list of plugins to execute at the beginning of every build. Take the forms of '[\"first\", \"second\", ...]'\n    \n    \n      BOOKENDS_TEARDOWN\n      None\n      The ordered list of plugins to execute at the end of every build. Take the forms of '[\"first\", \"second\", ...]'\n    \n  \n\n\n# config/local.yaml\nbookends:\n    setup:\n        - scm\n        - my-custom-bookend\n\n\n\nServing\n\nConfigure the how the service is listening for traffic.\n\n\n  \n    \n      Key\n      Default\n      Description\n    \n  \n  \n    \n      PORT\n      80\n      Port to listen on\n    \n    \n      HOST\n      0.0.0.0\n      Host to listen on (set to localhost to only accept connections from this machine)\n    \n    \n      URI\n      http://localhost:80\n      Externally routable URI (usually your load balancer or CNAME)\n    \n    \n      HTTPD_TLS\n      false\n      SSL support; for SSL, replace false with a JSON object that provides the options required by tls.createServer\n    \n  \n\n\n# config/local.yaml\nhttpd:\n    port: 443\n    host: 0.0.0.0\n    uri: https://localhost\n    tls:\n        key: |\n            PRIVATE KEY HERE\n        cert: |\n            YOUR CERT HERE\n\n\n\nEcosystem\n\nSpecify externally routable URLs for your UI, Artifact Store, and Badge service.\n\n\n  \n    \n      Key\n      Default\n      Description\n    \n  \n  \n    \n      ECOSYSTEM_UI\n      https://cd.screwdriver.cd\n      URL for the User Interface\n    \n    \n      ECOSYSTEM_STORE\n      https://store.screwdriver.cd\n      URL for the Artifact Store\n    \n    \n      ECOSYSTEM_BADGES\n      https://img.shields.io/badge/build–.svg\n      URL with templates for status text and color\n    \n  \n\n\n# config/local.yaml\necosystem:\n    # Externally routable URL for the User Interface\n    ui: https://cd.screwdriver.cd\n    # Externally routable URL for the Artifact Store\n    store: https://store.screwdriver.cd\n    # Badge service (needs to add a status and color)\n    badges: https://img.shields.io/badge/build--.svg\n\n\n\nDatastore Plugin\n\nTo use Postgres, MySQL, and Sqlite, use sequelize plugin.\n\nSequelize\nSet these environment variables:\n\n\n  \n    \n      Environment name\n      Required\n      Default Value\n      Description\n    \n  \n  \n    \n      DATASTORE_PLUGIN\n      Yes\n       \n      Set to sequelize\n    \n    \n      DATASTORE_SEQUELIZE_DIALECT\n      No\n      mysql\n      Can be sqlite, postgres, mysql, or mssql\n    \n    \n      DATASTORE_SEQUELIZE_DATABASE\n      No\n      screwdriver\n      Database name\n    \n    \n      DATASTORE_SEQUELIZE_USERNAME\n      No for sqlite\n       \n      Login username\n    \n    \n      DATASTORE_SEQUELIZE_PASSWORD\n      No for sqlite\n       \n      Login password\n    \n    \n      DATASTORE_SEQUELIZE_STORAGE\n      Yes for sqlite\n       \n      Storage location for sqlite\n    \n    \n      DATASTORE_SEQUELIZE_HOST\n      No\n       \n      Network host\n    \n    \n      DATASTORE_SEQUELIZE_PORT\n      No\n       \n      Network port\n    \n  \n\n\n# config/local.yaml\ndatastore:\n    plugin: sequelize\n    sequelize:\n        dialect: TYPE-OF-SERVER\n        storage: STORAGE-LOCATION\n        database: DATABASE-NAME\n        username: DATABASE-USERNAME\n        password: DATABASE-PASSWORD\n        host: NETWORK-HOST\n        port: NETWORK-PORT\n\n\n\nExecutor Plugin\n\nWe currently support kubernetes,  docker, VMs in Kubernetes, and Jenkins executor. See the custom-environment-variables file for more details.\n\nKubernetes\nSet these environment variables:\n\n\n  \n    \n      Environment name\n      Default Value\n      Description\n    \n  \n  \n    \n      EXECUTOR_PLUGIN\n      k8s\n      Default executor (eg: k8s, docker, k8s-vm, jenkins)\n    \n    \n      LAUNCH_VERSION\n      stable\n      Launcher version to use\n    \n    \n      EXECUTOR_K8S_ENABLED\n      true\n      Flag to enable Kubernetes executor\n    \n    \n      K8S_HOST\n      kubernetes.default\n      Kubernetes host\n    \n    \n      K8S_TOKEN\n      Loaded from /var/run/secrets/kubernetes.io/serviceaccount/token by default\n      JWT for authenticating Kubernetes requests\n    \n    \n      K8S_JOBS_NAMESPACE\n      default\n      Jobs namespace for Kubernetes jobs URL\n    \n  \n\n\n# config/local.yaml\nexecutor:\n    plugin: k8s\n    k8s:\n        options:\n            kubernetes:\n                # The host or IP of the kubernetes cluster\n                host: YOUR-KUBERNETES-HOST\n                token: JWT-FOR-AUTHENTICATING-KUBERNETES-REQUEST\n                jobsNamespace: default\n            launchVersion: stable\n\n\n\nDocker\nOr set these environment variables:\n\n\n  \n    \n      Environment name\n      Default Value\n      Description\n    \n  \n  \n    \n      EXECUTOR_PLUGIN\n      k8s\n      Default executor. Set to docker\n    \n    \n      LAUNCH_VERSION\n      stable\n      Launcher version to use\n    \n    \n      EXECUTOR_DOCKER_ENABLED\n      true\n      Flag to enable Docker executor\n    \n    \n      EXECUTOR_DOCKER_DOCKER\n      {}\n      Dockerode configuration (JSON object)\n    \n  \n\n\n# config/local.yaml\nexecutor:\n    plugin: docker\n    docker:\n        options:\n            docker:\n                socketPath: /var/lib/docker.sock\n            launchVersion: stable\n\n\n\nEmail Notifications\n\nConfigure the SMTP server and sender address that email notifications will be sent from.\n\n# config/local.yaml\nnotifications:\n    email:\n        host: smtp.yourhost.com\n        port: 25\n        from: example@email.com\n\n\n\nConfigurable authentication settings have not yet been built, but can easily be added. We’re using the nodemailer package to power emails, so authentication features will be similar to any typical nodemailer setup. Contribute at: https://github.com/screwdriver-cd/notifications-email\n\nSource Control Plugin\n\nWe currently support Github and Github Enterprise, Bitbucket.org, and Gitlab\n\nNote: Gitlab is a user-created plugin\n\nStep 1: Set up your OAuth Application\nYou will need to set up an OAuth Application and retrieve your OAuth Client ID and Secret.\n\nGithub:\n\n  Navigate to the Github OAuth applications page.\n  Click on the application you created to get your OAuth Client ID and Secret.\n  Fill out the Homepage URL and Authorization callback URL to be the IP address of where your API is running.\n\n\nBitbucket.org:\n\n  Navigate to the Bitbucket OAuth applications: https://bitbucket.org/account/user/{your-username}/api\n  Click on Add Consumer.\n  Fill out the URL and Callback URL to be the IP address of where your API is running.\n\n\nStep 2: Configure your SCM plugin\nSet these environment variables:\n\n\n  \n    \n      Environment name\n      Required\n      Default Value\n      Description\n    \n  \n  \n    \n      SCM_SETTINGS\n      Yes\n      {}\n      JSON object with SCM settings\n    \n  \n\n\nGithub:\n# config/local.yaml\nscms:\n    github:\n        plugin: github\n        config:\n            oauthClientId: YOU-PROBABLY-WANT-SOMETHING-HERE # The client id used for OAuth with github. GitHub OAuth (https://developer.github.com/v3/oauth/)\n            oauthClientSecret: AGAIN-SOMETHING-HERE-IS-USEFUL # The client secret used for OAuth with github\n            secret: SUPER-SECRET-SIGNING-THING # Secret to add to GitHub webhooks so that we can validate them\n            gheHost: github.screwdriver.cd # [Optional] GitHub enterprise host\n            username: sd-buildbot # [Optional] Username for code checkout\n            email: dev-null@screwdriver.cd # [Optional] Email for code checkout\n            privateRepo: false # [Optional] Set to true to support private repo; will need read and write access to public and private repos (https://developer.github.com/v3/oauth/#scopes)\n\n\n\nIf users want to use private repo, they also need to set up SCM_USERNAME and SCM_ACCESS_TOKEN as secrets in their screwdriver.yaml.\n\nBitbucket.org\n# config/local.yaml\nscms:\n    bitbucket:\n        plugin: bitbucket\n        config:\n            oauthClientId: YOUR-APP-KEY\n            oauthClientSecret: YOUR-APP-SECRET\n\n\n\nExtending the Docker container\n\nThere are some scenarios where you would prefer to extend the Screwdriver.cd Docker image, such as using custom Bookend plugins. This section is not meant to be exhaustive or complete, but will provide insight into some of the fundamental cases.\n\nUsing a custom bookend\n\nUsing a custom bookend is a common case where you would extend the Screwdriver.cd Docker image.\n\nIn this chosen example, we want to have our bookend execute before the scm (which checks out the code from the configured SCM). Although the bookend plugins can be configured by environment variables, we will show how to accomplish the same task with a local.yaml file.\n\nThis is shown in the following local.yaml snippet:\n\n# local.yaml\n---\n  ...\nbookends:\n  setup:\n    - my-custom-bookend\n    - scm\n\n\n\nFor building our extended Docker image, we will need to create a Dockerfile that will have our extra dependencies installed. If you would prefer to save the local.yaml configuration file in the Docker image instead of mounting it in later, you may do so in the Dockerfile as well.\n\n# Dockerfile\nFROM screwdrivercd/screwdriver:stable\n\n# Install additional NPM bookend plugin\nRUN cd /usr/src/app &amp;&amp; /usr/local/bin/npm install my-custom-bookend\n\n# Optionally save the configuration file in the image\nADD local.yaml /config/local.yaml\n\n\nOnce you build the Docker image, you will need to deploy it to your Screwdriver.cd cluster. For instance, if you’re using Kubernetes, you would replace the screwdrivercd/api:stable image to your custom Docker image.\n\nThe following is an example snippet of an updated Kubernetes deployment configuration:\n\n# partial Kubernetes configuration\n  ...\nspec:\n  replicas: 1\n  template:\n    spec:\n      containers:\n      - name: screwdriver-api\n        # The image name is the one you specified when built\n        # The tag name is the tag you specified when built\n        image: my_extended_docker_image_name:tag_name\n\n\n",
id: 7
});

index.add({
title: "APIの管理",
content: "APIの管理\n\nパッケージ\n\n他のサービスのように、APIは8080番ポートをexposeしたDockerイメージを提供しています。\n\n$ docker run -d -p 9000:8080 screwdrivercd/screwdriver:stable\n$ open http://localhost:9000\n\n\n\nこのDockerイメージはそのバージョン(例: 1.2.3)や動的なlatest・ stableでタグ付けされています。特に理由がなければstableまたは固定のバージョンタグを利用してください。\n\n設定\n\nScrewdriverは最初から多くのデフォルト設定がされていますが、config/local.yaml や環境変数を使うことでデフォルト設定を上書きできます。設定できる全ての環境変数はこちらに定義されています。\n\n認証 / 認可\n\n誰がAPIにアクセスでき、何ができるかを設定します。\n\n\n  \n    \n      キー\n      必須\n      説明\n    \n  \n  \n    \n      SECRET_JWT_PRIVATE_KEY\n      はい\n      JWTに署名するための秘密鍵です。次のコマンドにより生成できます。$ openssl genrsa -out jwt.pem 2048\n    \n    \n      SECRET_JWT_PUBLIC_KEY\n      はい\n      署名を検証するための公開鍵です。次のコマンドにより生成できます。$ openssl rsa -in jwt.pem -pubout -out jwt.pub\n    \n    \n      SECRET_COOKIE_PASSWORD\n      はい\n      セッションデータを暗号化するためのパスワードです。32文字以上である必要があります。\n    \n    \n      SECRET_PASSWORD\n      はい\n      SECRETを暗号化するためのパスワードです。32文字以上である必要があります。\n    \n    \n      IS_HTTPS\n      いいえ\n      サーバーがhttpsで動作しているかどうかを設定するフラグです。OAuthフローのフラグとして利用されます。(デフォルトはfalseです)\n    \n    \n      SECRET_WHITELIST\n      いいえ\n      システムに対して認証できるユーザのホワイトリストです。空の場合は全ユーザを許可します。(JSONの配列形式)\n    \n    \n      SECRET_ADMINS\n      いいえ\n      システムに対して認証できるユーザのホワイトリストです。空の場合は全ユーザを許可します。(JSONの配列形式)\n    \n  \n\n\n# config/local.yaml\nauth:\n    jwtPrivateKey: |\n        PRIVATE KEY HERE\n    jwtPublicKey: |\n        PUBLIC KEY HERE\n    cookiePassword: 975452d6554228b581bf34197bcb4e0a08622e24\n    encryptionPassword: 5c6d9edc3a951cda763f650235cfc41a3fc23fe8\n    https: false\n    whitelist:\n        - github:batman\n        - github:robin\n    admins:\n        - github:batman\n\n\n\nBookend Plugins\n\nビルド中に使用されるブックエンドプラグインを設定できます。デフォルトではscmが有効になっており、SCMのcheckoutコマンドでビルドを開始します。\n\nで開発したブックエンドを使用したい場合はこちらをご覧ください。\n\n\n  \n    \n      キー\n      デフォルト\n      説明\n    \n  \n  \n    \n      BOOKENDS_SETUP\n      None\n      ビルドの最初に実行されるプラグインの順番付きリストです。以下の書式で記述します。 '[\"first\", \"second\", ...]'\n    \n    \n      BOOKENDS_TEARDOWN\n      None\n      ビルドの終わりに実行されるプラグインの順番付きリストです。以下の書式で記述します。'[\"first\", \"second\", ...]'\n    \n  \n\n\n# config/local.yaml\nbookends:\n    setup:\n        - scm\n        - my-custom-bookend\n\n\n\n配信\n\nサービスがどのようにトラフィックを受け付けるかを設定します。\n\n\n  \n    \n      キー\n      デフォルト\n      説明\n    \n  \n  \n    \n      PORT\n      80\n      listenするポート\n    \n    \n      HOST\n      0.0.0.0\n      listenするホスト（そのマシン上からの接続だけを受け付けるときだけlocalhostに設定）\n    \n    \n      URI\n      http://localhost:80\n      外部から接続可能なURI (通常はロードバランサーやCNAME)\n    \n    \n      HTTPD_TLS\n      false\n      SSLサポートの有無です。有効にする場合はfalseをtls.createServerに渡すJSONオブジェクトに置き換えてください。\n    \n  \n\n\n# config/local.yaml\nhttpd:\n    port: 443\n    host: 0.0.0.0\n    uri: https://localhost\n    tls:\n        key: |\n            PRIVATE KEY HERE\n        cert: |\n            YOUR CERT HERE\n\n\n\nエコシステム\n\n外部からアクセス可能なUI、アーティファクトストア、バッジサービスのURLを指定します。\n\n\n  \n    \n      キー\n      デフォルト\n      説明\n    \n  \n  \n    \n      ECOSYSTEM_UI\n      https://cd.screwdriver.cd\n      ユーザーインターフェースのURL\n    \n    \n      ECOSYSTEM_STORE\n      https://store.screwdriver.cd\n      アーティファクトストアURL\n    \n    \n      ECOSYSTEM_BADGES\n      https://img.shields.io/badge/build–.svg\n      ステータステキストと色をテンプレートにしたURL\n    \n  \n\n\n# config/local.yaml\necosystem:\n    # Externally routable URL for the User Interface\n    ui: https://cd.screwdriver.cd\n    # Externally routable URL for the Artifact Store\n    store: https://store.screwdriver.cd\n    # Badge service (needs to add a status and color)\n    badges: https://img.shields.io/badge/build--.svg\n\n\n\nデータストアプラグイン\n\nPostgres, MySQL, や Sqlite を使用するにはsequelizeプラグインを使用します。\n\nSequelize\n\n下記の環境変数を設定します。\n\n\n  \n    \n      環境変数名\n      必須\n      デフォルト値\n      説明\n    \n  \n  \n    \n      DATASTORE_PLUGIN\n      はい\n       \n      sequelizeを指定\n    \n    \n      DATASTORE_SEQUELIZE_DIALECT\n      いいえ\n      mysql\n      sqlite, postgres, mysql, または mssql が指定可能\n    \n    \n      DATASTORE_SEQUELIZE_DATABASE\n      いいえ\n      screwdriver\n      データベース名\n    \n    \n      DATASTORE_SEQUELIZE_USERNAME\n      sqliteでは不要\n       \n      ログインユーザー名\n    \n    \n      DATASTORE_SEQUELIZE_PASSWORD\n      sqliteでは不要\n       \n      ログインパスワード\n    \n    \n      DATASTORE_SEQUELIZE_STORAGE\n      sqliteのみ必要\n       \n      sqliteのストレージの場所\n    \n    \n      DATASTORE_SEQUELIZE_HOST\n      いいえ\n       \n      ネットワークホスト\n    \n    \n      DATASTORE_SEQUELIZE_PORT\n      いいえ\n       \n      ネットワークホスト\n    \n  \n\n\n# config/local.yaml\ndatastore:\n    plugin: sequelize\n    sequelize:\n        dialect: TYPE-OF-SERVER\n        storage: STORAGE-LOCATION\n        database: DATABASE-NAME\n        username: DATABASE-USERNAME\n        password: DATABASE-PASSWORD\n        host: NETWORK-HOST\n        port: NETWORK-PORT\n\n\n\nExecutorプラグイン\n\n現在はkubernetes と docker と VMs in Kubernetes と Jenkins executor をサポートしています。\n\nKubernetes\n\n下記の環境変数を設定します。\n\n\n  \n    \n      環境変数名\n      デフォルト値\n      説明\n    \n  \n  \n    \n      EXECUTOR_PLUGIN\n       \n      k8sを設定します\n    \n    \n      LAUNCH_VERSION\n       \n      使用するLauncherのバージョン\n    \n    \n      K8S_HOST\n       \n      Kubernetesのホスト\n    \n    \n      K8S_TOKEN\n       \n      Kubernetesのリクエストを認証するためのJWT\n    \n    \n      K8S_JOBS_NAMESPACE\n      default\n      Kubernetesジョブ用ネームスペース\n    \n  \n\n\n# config/local.yaml\nexecutor:\n    plugin: k8s\n    k8s:\n        options:\n            kubernetes:\n                # The host or IP of the kubernetes cluster\n                host: YOUR-KUBERNETES-HOST\n                token: JWT-FOR-AUTHENTICATING-KUBERNETES-REQUEST\n                jobsNamespace: default\n            launchVersion: stable\n\n\n\nDocker\n\n下記の環境変数を設定します。\n\n\n  \n    \n      環境変数名\n      デフォルト値\n      説明\n    \n  \n  \n    \n      EXECUTOR_PLUGIN\n      docker\n      dockerを指定します\n    \n    \n      LAUNCH_VERSION\n      stable\n      使用するLauncherのバージョン\n    \n    \n      EXECUTOR_DOCKER_DOCKER\n      {}\n      Dockerode の設定 (JSONオブジェクト)\n    \n  \n\n\n# config/local.yaml\nexecutor:\n    plugin: docker\n    docker:\n        options:\n            docker:\n                socketPath: /var/lib/docker.sock\n            launchVersion: stable\n\n\n\nEmail通知\n\nSMTPサーバとEmail通知を行う送信者のアドレスを設定します。\n\n# config/local.yaml\nnotifications:\n    email:\n        host: smtp.yourhost.com\n        port: 25\n        from: example@email.com\n\n\n\n認証の設定はまだ実装されていませんが、追加することは難しくないでしょう。我々はnodemailerパッケージを使用しているため、認証機能はよくあるnodemailerのセットアップと同様です。コントリビューションお待ちしています:https://github.com/screwdriver-cd/notifications-email\n\nソース管理プラグイン\n\n現在はGithub と Bitbucket.orgをサポートしています。\n\nステップ1: OAuthアプリケーションをセットアップ\n\nOAuthアプリケーションのセットアップと、OAuth Client ID及びSecretの取得が必要です。\n\nGithub:\n\n\n  Github OAuth applications ページを開きます。\n  作成したアプリケーションをクリックし、OAuth Client IDとSecretを取得します。\n  APIが動作しているホストのIPアドレスをHomepage URL とAuthorization callback URLに入力します。\n\n\nBitbucket.org:\n\n\n  Navigate to the Bitbucket OAuth applications: https://bitbucket.org/account/user/{your-username}/api\n  Add Consumerをクリックします。\n  APIが動作しているホストのIPアドレスをURL と Callback URL に入力します。\n\n\nステップ2:SCMプラグインの設定\n\n下記の環境変数を設定します。\n\n\n  \n    \n      環境変数名\n      必須\n      デフォルト値\n      説明\n    \n  \n  \n    \n      SCM_SETTINGS\n      はい\n      {}\n      JSON object with SCM settings\n    \n  \n\n\nGithub:\n\n# config/local.yaml\nscms:\n    github:\n        plugin: github\n        config:\n            oauthClientId: YOU-PROBABLY-WANT-SOMETHING-HERE # OAuth Client ID (アプリケーションキー)\n            oauthClientSecret: AGAIN-SOMETHING-HERE-IS-USEFUL # OAuth Client Secret (アプリケーションsecret)\n            secret: SUPER-SECRET-SIGNING-THING # webhooks署名用のパスワード(secret)\n            gheHost: github.screwdriver.cd # [Optional] Github Enterpriseの場合のGHEホスト\n            username: sd-buildbot # [Optional] checkoutするユーザネーム\n            email: dev-null@screwdriver.cd # [Optional] checkoutするユーザのEmailアドレス\n            privateRepo: false # [Optional] プライベートレポジトリの read/write権限\n\n\n\nプライベートレポジトリを使用する場合は、SCM_USERNAME と SCM_ACCESS_TOKEN を secrets として screwdriver.yamlに記述する必要があります。\n\nBitbucket.org\n\n# config/local.yaml\nscms:\n    bitbucket:\n        plugin: bitbucket\n        config:\n            oauthClientId: YOUR-APP-KEY\n            oauthClientSecret: YOUR-APP-SECRET\n\n\n\nDockerコンテナの拡張\n\nScrewdriver.cdのDockerイメージを拡張したい場合は、カスタムBookendプラグインを使用してください。この章で全てをお伝えすることはできないですが、基本的な利用方法はお伝えできるでしょう。\n\nカスタムbookendを使用する\n\nScrewdriver.cdのDokcerイメージを拡張したい場合、カスタムbookendが使用できます。\n\n今回の例では、カスタムbookendをscmの前に実行します (設定されたSCMからコードをチェックアウトします)。bookendプラグインも環境変数で設定できるのですが、local.yamlを使って設定していきます。\n\n以下にlocal.yamlの例を示します。\n\n# local.yaml\n---\n  ...\nbookends:\n  setup:\n    - my-custom-bookend\n    - scm\n\n\n\n拡張したDockerイメージをビルドするために、追加の依存をインストールするDockerfileの作成が必要です。もしlocal.yamlを後でマウントするのではなくDockerイメージに保存したければ、以下のようにDockerfileを作成してください。\n\n# Dockerfile\nFROM screwdrivercd/screwdriver:stable\n# Install additional NPM bookend plugin\nRUN cd /usr/src/app &amp;&amp; /usr/local/bin/npm install my-custom-bookend\n# Optionally save the configuration file in the image\nADD local.yaml /config/local.yaml\n\n\nDockerイメージをビルドしたら、Screwdriver.cdのクラスタにデプロイする必要があります。例えば、Kubernetesを使用している場合は、screwdrivercd/api:stableを作成したDockerイメージで置き換えます。\n\n以下は、Kubernetesのデプロイ設定を更新する例です。\n\n# partial Kubernetes configuration\n  ...\nspec:\n  replicas: 1\n  template:\n    spec:\n      containers:\n      - name: screwdriver-api\n        # The image name is the one you specified when built\n        # The tag name is the tag you specified when built\n        image: my_extended_docker_image_name:tag_name\n\n\n",
id: 8
});

index.add({
title: "Configuring the Store",
content: "Managing the Store\n\nPackages\n\nLike the other services, the API is shipped as a Docker image with port 80 exposed.\n\n$ docker run -d -p 7000:80 screwdrivercd/store:stable\n$ open http://localhost:7000\n\n\n\nOur images are tagged for their version (eg. 1.2.3) as well as a floating latest and stable. Most installations should be using stable or the fixed version tags.\n\nConfiguration\n\nScrewdriver already defaults most configuration, but you can override defaults using a config/local.yaml or environment variables. All the possible environment variables are defined here.\n\nAuthentication\n\nConfigure the validation of incoming JWTs from the API.\n\n\n  \n    \n      Key\n      Default\n      Description\n    \n  \n  \n    \n      SECRET_JWT_PUBLIC_KEY\n      none\n      The public key used for verifying the signature of the JWT. Use the same one as configured in the API\n    \n  \n\n\n# config/local.yaml\nauth:\n    jwtPublicKey: |\n        PUBLIC KEY HERE\n\n\n\nServing\n\nConfigure the how the service is listening for traffic.\n\n\n  \n    \n      Key\n      Default\n      Description\n    \n  \n  \n    \n      PORT\n      80\n      Port to listen on\n    \n    \n      HOST\n      0.0.0.0\n      Host to listen on (set to localhost to only accept connections from this machine)\n    \n    \n      URI\n      http://localhost:80\n      Externally routable URI (usually your load balancer or CNAME)\n    \n    \n      HTTPD_TLS\n      false\n      SSL support; for SSL, replace false with a JSON object that provides the options required by tls.createServer\n    \n  \n\n\n# config/local.yaml\nhttpd:\n    port: 443\n    host: 0.0.0.0\n    uri: https://localhost\n    tls:\n        key: |\n            PRIVATE KEY HERE\n        cert: |\n            YOUR CERT HERE\n\n\n\nBuild Artifacts\n\nConfigure some settings about storing Build Artifacts.\n\n\n  \n    \n      Key\n      Default\n      Description\n    \n  \n  \n    \n      BUILDS_EXPIRE_TIME\n      1814400000 (3 weeks)\n      How long should build logs stay around for\n    \n    \n      BUILDS_MAX_BYTES\n      1073741824 (1GB)\n      Upper limit on incoming uploads to builds artifacts\n    \n  \n\n\n# config/local.yaml\nbuilds:\n    expiresInSec: 1814400000 # 3 weeks\n    maxByteSize: 1073741824 # 1GB\n\n\n\nStorage\n\nWe have two methods of storing artifacts right now: - memory - In-memory store (inefficient and non-permanent) - s3 - Amazon S3\n\n\n  \n    \n      Key\n      Default\n      Description\n    \n  \n  \n    \n      STRATEGY\n      memory\n      Method of storing artifacts (memory or s3)\n    \n    \n      S3_ACCESS_KEY_ID\n      none\n      Amazon access key\n    \n    \n      S3_ACCESS_KEY_SECRET\n      none\n      Amazon secret access key\n    \n    \n      S3_REGION\n      none\n      Amazon S3 region\n    \n    \n      S3_BUCKET\n      none\n      Amazon S3 bucket that you have write access to\n    \n    \n      S3_ENDPOINT\n      none\n      Custom endpoint for Amazon S3 compatible API\n    \n  \n\n\n# config/local.yaml\nstrategy:\n    plugin: memory\n    s3:\n        accessKeyId: YOUR-KEY-ID\n        secretAccessKey: YOUR-KEY-SECRET\n        region: YOUR-REGION\n        bucket: YOUR-BUCKET-ID\n        endpoint: YOUR-S3-API-URL\n\n\n",
id: 9
});

index.add({
title: "Storeの設定",
content: "Storeの管理\n\nパッケージ\n\n他のサービスと同様に、このAPIは80番ポートをexposeされたDockerイメージを提供しています。\n\n$ docker run -d -p 7000:80 screwdrivercd/store:stable\n$ open http://localhost:7000\n\n\n\nこのDockerイメージはそのバージョン(例: 1.2.3) や動的なlatest・stableでタグ付けされています。特に理由がなければstableまたは固定のバージョンタグを利用してください。\n\n設定\n\nScrewdriverはほとんどの設定がデフォルトとして設定されていますが、これらはconfig/local.yamlや環境変数を利用して上書きすることができます。利用可能な環境変数はこちらで定義されています。\n\n認証\n\nAPIから渡されるJWTのバリデーションについて設定します。\n\n\n  \n    \n      キー\n      デフォルト\n      説明\n    \n  \n  \n    \n      SECRET_JWT_PUBLIC_KEY\n      なし\n      JWTの署名を検証するために使用される公開鍵。APIと同じものを設定します。\n    \n  \n\n\n# config/local.yaml\nauth:\n    jwtPublicKey: |\n        PUBLIC KEY HERE\n\n\n\n配信\n\nサービスがどのようにトラフィックを受け付けるかを設定します。\n\n\n  \n    \n      キー\n      デフォルト\n      説明\n    \n  \n  \n    \n      PORT\n      80\n      listenするポート\n    \n    \n      HOST\n      0.0.0.0\n      listenするホスト(そのマシン上からの接続だけを受け付けるときだけlocalhostに設定)\n    \n    \n      URI\n      http://localhost:80\n      外部から接続可能なURI (通常はロードバランサーやCNAME)\n    \n    \n      HTTPD_TLS\n      false\n      SSLサポートの有無です。有効にする場合はfalseをtls.createServerに渡すJSONオブジェクトに置き換えてください。\n    \n  \n\n\n# config/local.yaml\nhttpd:\n    port: 443\n    host: 0.0.0.0\n    uri: https://localhost\n    tls:\n        key: |\n            PRIVATE KEY HERE\n        cert: |\n            YOUR CERT HERE\n\n\n\nビルドアーティファクト\n\nビルドアーティファクトの保存についての設定です。\n\n\n  \n    \n      キー\n      デフォルト\n      説明\n    \n  \n  \n    \n      BUILDS_EXPIRE_TIME\n      1814400000 (3週間)\n      ビルドログが保存される期間\n    \n    \n      BUILDS_MAX_BYTES\n      1073741824 (1GB)\n      ビルドアーティファクトへのアップロード上限サイズ\n    \n  \n\n\n# config/local.yaml\nbuilds:\n    expiresInSec: 1814400000 # 3 weeks\n    maxByteSize: 1073741824 # 1GB\n\n\n\nストレージ\n\n現在、アーティファクトの保存には次の2つの方法があります。memory - インメモリストア（非効率・非永続）、 s3 - Amazon S3\n\n\n  \n    \n      キー\n      デフォルト\n      説明\n    \n  \n  \n    \n      STRATEGY\n      memory\n      アーティファクトを保存する方法(memoryまたはs3)\n    \n    \n      S3_ACCESS_KEY_ID\n      なし\n      Amazonアクセスキー\n    \n    \n      S3_ACCESS_KEY_SECRET\n      なし\n      Amazonシークレットアクセスキー\n    \n    \n      S3_REGION\n      なし\n      Amazon S3 のリージョン\n    \n    \n      S3_BUCKET\n      なし\n      書き込みアクセスを行うAmazon S3 のバケット\n    \n    \n      S3_ENDPOINT\n      なし\n      Amazon S3と互換性のある独自のエンドポイント\n    \n  \n\n\n# config/local.yaml\nstrategy:\n    plugin: memory\n    s3:\n        accessKeyId: YOUR-KEY-ID\n        secretAccessKey: YOUR-KEY-SECRET\n        region: YOUR-REGION\n        bucket: YOUR-BUCKET-ID\n        endpoint: YOUR-S3-API-URL\n\n\n",
id: 10
});

index.add({
title: "Configuring the UI",
content: "Managing the User Interface\n\nPackages\n\nLike the other services, the User Interface is shipped as a Docker image with port 80 exposed.\n\n$ docker run -d -p 8000:80 screwdrivercd/ui:stable\n$ open http://localhost:8000\n\n\n\nOur images are tagged for their version (eg. 1.2.3) as well as a floating latest and stable.  Most installations should be using stable or the fixed version tags.\n\nConfiguration\n\nThe User Interface only has one configuration option, the location of the API.  It is set via an environment variable ECOSYSTEM_API.\n\nExample:\n$ docker run -d -p 8000:80 -e ECOSYSTEM_API=http://localhost:9000 screwdrivercd/ui:stable\n\n\n",
id: 11
});

index.add({
title: "UIの設定",
content: "ユーザーインターフェースの管理\n\nパッケージ\n\n他のサービスと同様に、80番ポートがexposeされたDockerイメージとしてユーザーインターフェースを提供しています。\n\n$ docker run -d -p 8000:80 screwdrivercd/ui:stable\n$ open http://localhost:8000\n\n\n\nこのDockerイメージはそのバージョン(例: 1.2.3)や動的なlatest・stableでタグ付けされています。特に理由がなければstableまたは固定のバージョンタグを利用してください。\n\n設定\n\nユーザーインターフェースにはAPIのURLという1つの設定項目しかありません。設定には環境変数ECOSYSTEM_APIを利用します。\n\n例:\n\n$ docker run -d -p 8000:80 -e ECOSYSTEM_API=http://localhost:9000 screwdrivercd/ui:stable\n\n\n",
id: 12
});

index.add({
title: "Contributing",
content: "Contributing\n\nThank you for considering contributing! There are many ways you can help.\n\nBugs/Feature Requests\n\nFile an issue if you think you’ve found a bug or would like to request a feature. Be sure to describe:\n\n\n  How it can be reproduced\n  What did you expect to happen?\n  What actually happened?\n  Version, platform, etc. if relevant\n\n\nYou can file all issues with Screwdriver in the screwdriver repo; please tag with appropriate Github labels whenever possible. We will update any issues we’re working on with a daily summary. To see what we’re currently working on, you can check out our digital scrum board in the Projects section of the Screwdriver API repo.\n\nSubmitting Pull Requests\n\nPatches for fixes, features, and improvements are accepted through pull requests.\n\n\n  Write good commit messages in the present tense (“Add X”, not “Added X”) with a short title, blank line, and bullet points if needed. Capitalize the first letter of the title and any bullet items. No punctuation in the title.\n  Code must pass lint and style checks.\n  All external methods must be documented. Add README docs and/or user documentation in our guide when appropriate.\n  Include tests to improve coverage and prevent regressions.\n  Squash changes into a single commit per feature/fix. Ask if you’re unsure how to discretize your work.\n  Whenever possible, tag your pull request with appropriate Github labels.\n\n\nPlease ask before embarking on a large improvement so you’re not disappointed if it does not align with the goals of the project or owner(s).\n\nCommit Message Format\n\nWe use semantic-release, which requires commit messages to be in this specific format: &lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;\n\n\n  \n    \n      Keyword\n      Description\n    \n  \n  \n    \n      Type\n      feat (feature), fix (bug fix), docs (documentation), style (formatting, missing semi colons, …), refactor, test (when adding missing tests), chore (maintain)\n    \n    \n      Scope\n      anything that specifies the scope of the commit; can be blank, the issue number that your commit pertains to, or *\n    \n    \n      Subject\n      description of the commit\n    \n  \n\n\nImportant: For any breaking changes that require a major version bump, add BREAKING CHANGE somewhere in the commit title or message.\n\nExamples commit titles:\n\n  For a bug fix: fix: Remove extra space\n  For a breaking change: feat(scm): Support new scm plugin. BREAKING CHANGE: github no longer works\n\n\nWhere to Contribute\n\nScrewdriver has a modular architecture, and the various responsibilities are split up into separate repos.\n\nCheck out the architecture diagram to see the overall workflow of Continuous Delivery using Screwdriver. The next few sections will help lay out where different code repositories fit.\n\nScrewdriver API\nThe screwdriver repo is the core of screwdriver, providing the API endpoints for everything that screwdriver does. The API is based on the hapijs framework and is implemented in node as a series of plugins.\n\n\n  Build bookends allow a user to create setup and teardown steps for builds.\n  The API can also send notifications to users. notifications-base is the base class for defining the behavior between screwdriver and notifications plugins, like email notifications.\n\n\nLauncher\n\nThe launcher performs step execution and housekeeping internal to build containers. This is written in Go and mounted into build containers as a binary.\n\n\n  sd-step: A Shared Step allows people to use the same packages and commands in all build containers, regardless of build environment\n  meta-cli: A Go-based CLI for reading/writing information from the metadata\n\n\nExecutors\n\nAn executor is used to manage build containers for any given job. Several implementations of executors have been created. All are designed to follow a common interface. Executor implementations are written in node:\n\n\n  executor-base: Common interface\n  executor-docker: Docker implementation\n  executor-j5s: Jenkins implementation\n  executor-k8s: Kubernetes implementation\n  executor-k8s-vm: Kubernetes VM implementation\n\n\nThe executor router is a generic executor plugin that routes builds to a specified executor.\n\nModels\n\nThe object models provide the definition of the data that is saved in datastores (analogous to databases). This is done in two parts:\n\n\n  data-schema: Schema definition with Joi\n  models: Specific business logic around the data schema\n\n\nDatastores\n\nA datastore implementation is used as the interface between the API and a data storage mechanism. There are several implementations written in node around a common interface.\n\n\n  datastore-base: Base class defining the interface for datastore implementations\n  datastore-sequelize: MySQL, PostgreSQL, SQLite3, and MS SQL implementations\n  datastore-dynamodb: DynamoDB implementation, with dynamic-dynamodb being used to create the datastore tables for it\n\n\nArtifacts\n\nThe Artifact Store (not to be confused with the datastores mentioned above) is used for saving log outputs, shared steps, templates, test coverage, and any artifacts that are generated during a build. The log service is a Go tool for reading logs from the Launcher and uploading them to the store. The artifact-bookend is used for uploading artifacts to the store.\n\nSource Code Management\n\nAn SCM implementation is used as the interface between the API and an SCM. There are several implementations written in nodejs around a common interface.\n\n\n  scm-base: Common interface\n  scm-bitbucket: Bitbucket implementation\n  scm-github: Github implementation\n\n\nTemplates\n\nTemplates are snippets of predefined code that people can use to replace a job definition in their screwdriver.yaml. A template contains a series of predefined steps along with a selected Docker image.\n\n\n  templates: A repo for all build templates\n  template-main: The CLI for validating and publishing job templates\n  template-validator: A tool used by the API to validate a job template\n\n\nConfig Parser\n\nNode module for validating and parsing user’s screwdriver.yaml configurations.\n\nGuide &amp; Homepage\n\nThe Guide is documentation! Everything you ever hoped to know about the Screwdriver project.\nThe Homepage is the basic one-pager that powers Screwdriver.cd.\n\nUI\n\nThe Ember-based user interface of Screwdriver.\n\nMiscellaneous Tools\n\n\n  circuit-fuses: Wrapper to provide a node-circuitbreaker with callback interface\n  client: Simple Go-based CLI for accessing the Screwdriver API\n  gitversion: Go-based tool for updating git tags on a repo for a new version number\n  keymbinatorial: Generates the unique combinations of key values by taking a single value from each keys array\n  toolbox: Repository for handy Screwdriver-related scripts and other tools\n  hashr: Wrapper module for generating ids based on a hash\n\n\nAdding a New Screwdriver Repo\n\nWe have some tools to help start out new repos for screwdriver:\n\n\n  generator-screwdriver: Yeoman generator that bootstraps new repos for screwdriver\n  eslint-config-screwdriver: Our ESLint rules for node-based code. Included in each new repo as part of the bootstrap process\n\n\nIf you create a new repo, please come back and edit this page so that others can know where your repo fits in.\n\nScrewdriver.cd Tests and Examples\n\nThe organization screwdriver-cd-test contains various example repos/screwdriver.yamls and acceptance tests for Screwdriver.cd.\n\n",
id: 13
});

index.add({
title: "貢献する",
content: "貢献する\n\nContributingを考えてくれてありがとうございます！支援にはたくさんの方法があります。\n\nIssues\n\nバグと思われるものを発見した場合は、以下を記述してIsuueを投稿してください。\n\n\n  どのようにすると再現しますか？\n  予期した動きはどのようなものでしたか？\n  実際には何が起こりましたか？\n  VersionやPlatformなど、その他関連のありそうなもの。\n\n\nYou can file all issues with Screwdriver in the screwdriver repo. We will update any issues we’re working on with a daily summary. To see what we’re currently working on, you can check out our digital scrum board in the Projects section in the Screwdriver API repo.\n\nドキュメント\n\nドキュメント、README、サンプルは非常に重要です。是非それらの改善にご協力お待ちしておりますので、タイポを見つけたり問題に気づきましたら、気軽に修正点を送っていただくかお声掛け下さい。\n\nパッチの送信\n\nPatches for fixes, features, and improvements are accepted through pull requests.\n\n\n  Write good commit messages, in the present tense! (Add X, not Added X). Short title, blank line, bullet points if needed. Capitalize the first letter of the title or bullet item. No punctuation in the title.\n  Code must pass lint and style checks.\n  All external methods must be documented. Add README docs and/or user documentation in our guide when appropriate.\n  Include tests to improve coverage and prevent regressions.\n  Squash changes into a single commit per feature/fix. Ask if you’re unsure how to discretize your work.\n\n\nPlease ask before embarking on a large improvement so you’re not disappointed if it does not align with the goals of the project or owner(s).\n\nCommit Message Format\n\nWe use semantic-release, which requires commit messages to be in this specific format: &lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;\n\n\n  Types:\n    \n      feat (feature)\n      fix (bug fix)\n      docs (documentation)\n      style (formatting, missing semi colons, …)\n      refactor\n      test (when adding missing tests)\n      chore (maintain)\n    \n  \n  Scope: anything that specifies the scope of the commit. Can be blank or *\n  Subject: description of the commit. For breaking changes that require major version bump, add BREAKING CHANGE to the commit message.\n\n\nExamples commit messages:\n\n\n  Bug fix: fix: Remove extra space\n  Breaking change: feat(scm): Support new scm plugin. BREAKING CHANGE: github no longer works\n\n\n機能のリクエスト\n\nMake the case for a feature via an issue with a good title. The feature should be discussed and given a target inclusion milestone or closed.\n\nWhere to Contribute\n\nScrewdriver has a modular architecture, and the various responsibilities are split up in separate repos.\n\nScrewdriver API  \n\nThe screwdriver repo is the core of screwdriver, providing the API endpoints for everything that screwdriver does. The API is based on the hapijs framework and is implemented in node as a series of plugins.\n\nLauncher\n\nThe launcher performs step execution and housekeeping internal to build containers. This is written in Go, and mounted into build containers as a binary.\n\nExecutors\n\nAn executor is used to manage build containers for any given job. Several implementations of executors have been created. All are designed to follow a common interface. Executor implementations are written in node:\n\n\n  executor-base: Common interface \n  executor-docker: Docker implementation \n  executor-j5s: Jenkins implementation \n  executor-k8s: Kubernetes implementation \n\n\nModels\n\nThe object models provide the definition of the data that is stored in data stores. This is done in two parts:\n\n\n  data-schema: Schema definition with Joi \n  models: Specific business logic around the data schema \n\n\nDatastores\n\nA datastore implementation is used as the interface between the API and a data storage mechanism. There are several implementations written in node around a common interface.\n\n\n  datastore-base: Common interface \n  datastore-sequelize: Mysql, postgres, sqlite3 and mssql implementation \n\n\nScms\n\nAn scm implementation is used as the interface between the API and an scm. There are several implementations written in node around a common interface.\n\n\n  scm-base: Common interface \n  scm-bitbucket: Bitbucket implementation \n  scm-github: Github implementation \n\n\nConfig Parser \n\nNode module for validating and parsing user’s screwdriver.yaml configurations.\n\nGuide\n\nThis documentation! Everything you ever hoped to know about the Screwdriver project.\n\nMiscellaneous Tools\n\n\n  client: Simple Go-based CLI for accessing the Screwdriver API\n  gitversion: Go-based tool for updating git tags on a repo for a new version number\n  circuit-fuses: Wrapper to provide a node-circuitbreaker w/ callback interface \n  keymbinatorial: Generates the unique combinations of key values by taking a single value from each keys array \n\n\nAdding a New Screwdriver Repo\n\nWe have some tools to help start out new repos for screwdriver:\n\n\n  generator-screwdriver: Yeoman generator that bootstraps new repos for screwdriver\n  eslint-config-screwdriver: Our eslint rules for node-based code. Included in each new repo as part of the bootstrap process\n\n",
id: 14
});

index.add({
title: "Domain Model",
content: "Domain Model\n\nNote: Parallel, series, and matrix have not been implemented yet. Everything will run in series by default.\n\n\n\n\nSource Code\n\nSource Code is a specified SCM repository and branch that contains a screwdriver.yaml and the code required to build, test, and publish your application.\n\nStep\n\nA step is a named action that needs to be performed, usually a single shell command. In essence, Screwdriver runs /bin/sh in your terminal then executes all the steps; in rare cases, different terminal/shell setups may have unexpected behavior. If the command finishes with a non-zero exit code, the step is considered a failure. Environment variables will be passed between steps, within the same job.\n\nContainer\n\nA container runs steps in an isolated environment. This is done in order to test the compatibility of code running in different environments with different versions, without affecting other builds that may be running at the same time. This is implemented using Docker containers.\n\nJob\n\nA job consists of executing multiple sequential steps inside a specified container. If any step in the series fails, then the entire job is considered failed and subsequent steps will be skipped (unless configured otherwise).\n\nJobs work by checking out the source code to a specified commit, setting the desired environment variables, and executing the specified steps.\n\nDuring the job, the executing steps share three pieces of context:\n\n\n  Filesystem\n  Container\n  Metadata\n\n\nJobs can be started automatically by changes made in the source code or triggered through the workflow. Jobs can also be started manually through the UI.\n\nPull Requests\n\nPull requests are run separately from existing pipeline jobs. They will only execute steps from the main job in the Screwdriver configuration.\n\nParallelization\n\nIt is possible to parallelize a job by defining a matrix of environment variables. These are usually used for testing against multiple containers or test types.\n\nIn this example job definition, 4 builds will run in parallel:\nimage: node:\nsteps:\n    test: npm run test-${TEST_TYPE}\nmatrix:\n    NODE_VERSION:\n        - 4\n        - 6\n    TEST_TYPE:\n        - unit\n        - functional\n\n\n\n\n  NODE_VERSION=4 and TEST_TYPE=unit\n  NODE_VERSION=4 and TEST_TYPE=functional\n  NODE_VERSION=6 and TEST_TYPE=unit\n  NODE_VERSION=6 and TEST_TYPE=functional\n\n\nBuild\n\nA build is an instance of a running job. All builds are assigned a unique build number. Each build is associated with an event. With a basic job configuration, only one build of a job will be running at any given time. If a job matrix is configured, then there can be multiple builds running in parallel.\n\nA build can be in one of five different states:\n\n\n  QUEUED - Build is waiting for available resources\n  RUNNING - Build is actively running on an executor\n  SUCCESS - All steps completed successfully\n  FAILURE - One of the steps failed\n  ABORTED - User canceled the running build\n\n\nEvent\n\nAn event represents a commit or a manual restart of a pipeline. There are 2 types of events:\n\n\n  pipeline: - Events created when a user manually restarts a pipeline or merges a pull request. This type of event triggers the same sequence of jobs as the pipeline’s workflow. For example: ['main', 'publish', 'deploy']\n  pr:  - Events created by opening or updating a pull request. This type of event only triggers the main job.\n\n\nMetadata\n\nMetadata is a structured key/value storage of relevant information about a build. Metadata will be shared with subsequent builds in the same workflow. It can be updated or retrieved throughout the build by using the built-in meta CLI in the steps.\n\nExample:\n$ meta set example.coverage 99.95\n$ meta get example.coverage\n99.95\n$ meta get example\n{\"coverage\":99.95}\n\n\n\nSee the metadata page for more information.\n\nWorkflow\n\nWorkflow is the order that jobs will execute in after a successful build of the main job. The main job will always run first. Jobs can be executed in parallel, series, or a combination of the two to allow for all possibilities. Workflow must contain all defined jobs in the pipeline.\n\nAll jobs executed in a given workflow share:\n\n\n  Source code checked out from the same git commit\n  Access to metadata from a main build that triggered or was selected for this job’s build\n\n\nIn the following example of a workflow section, this is the flow:\nworkflow:\n    - publish\n    - parallel:\n        - series:\n            - deploy-west\n            - validate-west\n        - series:\n            - deploy-east\n            - validate-east\n\n\n\nAfter the merge of a pull-request to master:\n\n\n  main will run and trigger publish\n  publish will trigger deploy-west and deploy-east in parallel\n  deploy-west will trigger validate-west\n  deploy-east will trigger validate-east\n\n\nPipeline\n\nA pipeline represents a collection of jobs that share the same source code. These jobs are executed in the order defined by the workflow.\n\nThe main job is required to be defined in every pipeline as it is the one that builds for each change made to the source code (and proposed changes).\n\n",
id: 15
});

index.add({
title: "ドメインモデル",
content: "ドメインモデル\n\n\n\n\nソースコード\n\nソースコードとは、ビルドやテスト、アプリケーションのパブリッシュに必要なコードとscrewdriver.yaml を含む、指定されたSCMリポジトリとブランチのことです。\n\nステップ\n\nA step is a named action that needs to be performed, usually a single shell command. In essence, Screwdriver runs /bin/sh in your terminal then executes all the steps; in rare cases, different terminal/shell setups may have unexpected behavior. If the command finishes with a non-zero exit code, the step is considered a failure. Environment variables will be passed between steps, within the same job.\n\nコンテナ\n\nコンテナは隔離された環境でステップを実行します。異なる環境・バージョンで動作しているコードの互換性について、同時に実行されている他のビルドに影響を与えずにテストするために行われます。これはDockerコンテナを利用して実装されています。\n\nジョブ\n\nジョブとは、順番が設定された複数のステップを指定されたコンテナで実行することです。一連のステップのうちいずれかが失敗すると、ジョブ全体は失敗されたとみなされ、以降のステップはスキップされます。（そのように設定されていない場合を除く）\n\n実際のジョブではソースコード の特定のコミットをチェックアウトし、求められた環境変数を設定し、指定されたステップを実行するという処理が行われます。\n\nジョブの実行中、実行されるステップでは次の3つのコンテキストが共有されます。\n\n\n  ファイルシステム\n  コンテナ\n  メタデータ\n\n\nジョブはソースコードへの変更やワークフローからのトリガーで自動的に開始します。UIから手動で開始することも可能です。\n\nPull Requests\n\nPull requests are run separately from existing pipeline jobs. They will only execute steps from the main job in the Screwdriver configuration.\n\n並列実行\n\n環境変数のマトリックスを定義することでジョブの並列実行が可能です。通常これは複数のコンテナやテストの種類が必要な際に利用されます。\n\nこのジョブの例では4つのビルドが並列に実行されます。\n\nimage: node:\nsteps:\n    test: npm run test-${TEST_TYPE}\nmatrix:\n    NODE_VERSION:\n        - 4\n        - 6\n    TEST_TYPE:\n        - unit\n        - functional\n\n\n\n\n  NODE_VERSION=4 and TEST_TYPE=unit\n  NODE_VERSION=4 and TEST_TYPE=functional\n  NODE_VERSION=6 and TEST_TYPE=unit\n  NODE_VERSION=6 and TEST_TYPE=functional\n\n\nビルド\n\nビルドは実行中のジョブジョブのインスタンスのことを指します。すべてのビルドはユニークなビルド番号が振られています。また、各ビルドはイベントイベントに紐づいています。基本的なジョブ設定の場合、ジョブに対し一度に一つのビルドが実行されます。ジョブマトリクスが設定されていれば複数のビルドが並列に実行されます。\n\nビルドは次の5つのうちいずれかの状態を持ちます。\n\n\n  QUEUED - ビルドはリソースの空きを待っています\n  RUNNING - ビルドはexecutorで実行されています\n  SUCCESS - 全てのステップが成功しました\n  FAILURE - いずれかのステップが失敗しました\n  ABORTED - ユーザーが実行中のビルドをキャンセルしました\n\n\nイベント\n\nイベントはコミットやパイプラインの手動リスタートを表します。イベントには下記の2種類があります。\n\n\n  pipeline: - パイプラインを手動で開始したりpull requestをマージしたりした場合に作られるイベントです。この種類のイベントは、パイプラインにおけるワークフローとしてのジョブと同じ順序でトリガーされます。(例: ['main', 'publish', 'deploy'])\n  pr:  - pull requestの作成や更新により作られるイベントです。この種類のイベントはmainジョブのみトリガーします。\n\n\nメタデータ\n\nMetadata is a structured key/value storage of relevant information about a build. Metadata will be shared with subsequent builds in the same workflow. It can be updated or retrieved throughout the build by using the built-in CLI (meta) in the steps.\n\nExample:\n\n$ meta set example.coverage 99.95\n$ meta get example.coverage\n99.95\n$ meta get example\n{\"coverage\":99.95}\n\n\n\nWorkflow\n\nワークフローとは、デフォルトブランチのmainジョブのビルド成功後に実行されるジョブの順番のことです。ジョブは並列や逐次、またはその組み合わせで実行することができます。ワークフローにはパイプライン内に定義されたジョブがすべて含まれている必要があります。\n\nワークフロー内で実行されるジョブは次の内容を共有します。\n\n\n  同じgitコミットからチェックアウトされたソースコード\n  Access to metadata from a main build that triggered or was selected for this job’s build\n\n\n下記のworkflowセクションの例ではこのようなフローになっていて\n\nworkflow:\n    - publish\n    - parallel:\n        - series:\n            - deploy-west\n            - validate-west\n        - series:\n            - deploy-east\n            - validate-east\n\n\n\npull-requestがmasterにマージされると次のように動作します。\n\n\n  mainが実行され、publishをトリガー\n  publishはdeploy-westとdeploy-eastを並列でトリガー\n  deploy-westはvalidate-westをトリガー\n  deploy-eastはvalidate-eastをトリガー\n\n\nパイプライン\n\nパイプラインとは同じソースコードを共有するジョブジョブの集合を表します。これらのジョブはワークフローで定義された順で実行されます。\n\nmainジョブはソースコードへの各種変更をビルドするものなので、全てのパイプラインに定義されている必要があります。\n",
id: 16
});

index.add({
title: "Environment Variables",
content: "Environment Variables\n\nScrewdriver exports a set of environment variables that you can rely on during the course of a build.\n\nNote: Environment variables set in one job cannot be accessed in another job. To pass variables between jobs, use metadata.\n\nBuild Specific\n\n\n  \n    \n      Name\n      Value\n    \n  \n  \n    \n      SD_PIPELINE_ID\n      The ID of your pipeline\n    \n    \n      SD_JOB_NAME\n      Job name (e.g.: main)\n    \n    \n      SD_BUILD_ID\n      Build number (e.g.: 1, 2, etc)\n    \n    \n      SD_PULL_REQUEST\n      Pull Request number (blank if non-PR)\n    \n    \n      SD_TOKEN\n      JWT token for the build\n    \n  \n\n\nDirectories\n\n\n  \n    \n      Name\n      Value\n    \n  \n  \n    \n      SD_SOURCE_DIR\n      Location of checked-out code\n    \n    \n      SD_ARTIFACTS_DIR\n      Location of built/generated files\n    \n  \n\n\nEnvironment Variables\n\n\n  \n    \n      Name\n      Value\n    \n  \n  \n    \n      &lt;environment_variable&gt;\n      Environment variable specified under the “environment” section in your screwdriver.yaml\n    \n  \n\n\nSource Code\n\n\n  \n    \n      Name\n      Value\n    \n  \n  \n    \n      SCM_URL\n      SCM URL that was checked out\n    \n  \n\n\nURLs\n\n\n  \n    \n      Name\n      Value\n    \n  \n  \n    \n      SD_API_URL\n      Link to the Screwdriver API URL\n    \n  \n\n\nContinuous Integration\n\n\n  \n    \n      Name\n      Value\n    \n  \n  \n    \n      SCREWDRIVER\n      true\n    \n    \n      CI\n      true\n    \n    \n      CONTINUOUS_INTEGRATION\n      true\n    \n  \n\n",
id: 17
});

index.add({
title: "Environment Variables",
content: "Environment Variables\n\nScrewdriver exports a set of environment variables that you can rely on during the course of a build.\n\nBuild Specific\n\n\n  \n    \n      Name\n      Value\n    \n  \n  \n    \n      SD_PIPELINE_ID\n      The ID of your pipeline\n    \n    \n      SD_JOB_NAME\n      Job name (e.g.: main)\n    \n    \n      SD_BUILD_ID\n      Build number (e.g.: 1, 2, etc)\n    \n    \n      SD_PULL_REQUEST\n      Pull Request number (blank if non-PR)\n    \n    \n      SD_TOKEN\n      JWT token for the build\n    \n  \n\n\nDirectories\n\n\n  \n    \n      Name\n      Value\n    \n  \n  \n    \n      SD_SOURCE_DIR\n      Location of checked-out code\n    \n    \n      SD_ARTIFACTS_DIR\n      Location of built/generated files\n    \n  \n\n\nEnvironment Variables\n\n\n  \n    \n      Name\n      Value\n    \n  \n  \n    \n      &lt;environment_variable&gt;\n      Environment variable specified under the “environment” section in your screwdriver.yaml\n    \n  \n\n\nソースコード\n\n\n  \n    \n      Name\n      Value\n    \n  \n  \n    \n      SCM_URL\n      SCM URL that was checked out\n    \n  \n\n\nURLs\n\n\n  \n    \n      Name\n      Value\n    \n  \n  \n    \n      SD_API_URL\n      Link to the Screwdriver API URL\n    \n  \n\n\nContinuous Integration\n\n\n  \n    \n      Name\n      Value\n    \n  \n  \n    \n      SCREWDRIVER\n      true\n    \n    \n      CI\n      true\n    \n    \n      CONTINUOUS_INTEGRATION\n      true\n    \n  \n\n",
id: 18
});

index.add({
title: "Execution Engines",
content: "Execution Engines\n\n\n  A workload management system for the scheduling and running of jobs.\n\n\nThe typical enterprise requires support for multiple operating systems.  A core tenet of the project is to leverage both open source projects and commercial cloud products and their capabilities where we can.\nTODO: Tie back to targeted use cases and typical enterprise\n\nSupported environments\n\nTier 1:\n\n\n  Linux and a typical use case of web serving and associated backend systems.  For the Open Source release we are evaluating a number of options as explained below.\n\n\nTier 2:\n\n\n  Mac OSX for iOS and desktop clients.  Windows may be supported in the future.  Jenkins will be a supported execution engine to handle scheduling across Mac OSX slaves.  Jenkins support across many OSes is useful here.\n\n\nWhy not Jenkins everywhere?  While Jenkins serves us well in other areas, it has issues scaling and limits overall performance with its architecture.  In addition, managing a Jenkins cluster has high operational overhead.  A downside to not using Jenkins is not having access to the existing plugin ecosystem.\n\nSelection Criteria\n\n\n  Availability outside of Yahoo\n  Ease of setup\n  Community momentum (leverage industry innovation and future proof our solution)\n  Capabilities (semi-persistent storage, scheduler options, etc)\n  Run on-premise or in cloud (AWS or GCP)\n  Operability\n\n\nCandidates\n\n\n  Kubernetes (also GCP’s Container Engine)\n  Amazon’s ECS\n  Mesos\n  Docker Swarm\n\n\nInitial analysis\n\n\n  Amazon ECS and Kubernetes had easiest setup.  This allows users to play with the platform easily.  These also have low operational overhead (if using GCP Container Engine in Kubernetes’ case) since they are cloud options.\n  Kubernetes allows us to have the same interface for on-premise use as well as a native supported interface in GCP.\n  ECS would limit us to Amazon and doesn’t have an on-premise option.\n  Mesos is used internally at Yahoo.  Getting started is more difficult. Need more time to investigate frameworks.\n  Docker Swarm is a candidate but is less mature than other options.  Something to keep an eye on.\n\n\nCapabilities analysis requires learning the underlying systems to a certain degree.  The evaluation process includes an end to end integration to understand integration points as well as the strength and weaknesses of the system.  Kubernetes was chosen for the first end to end integration.\n\nTODO: add results of evaluations\n",
id: 19
});

index.add({
title: "Execution Engines",
content: "Execution Engines\n\n\n  ジョブのスケジューリングと実行のためのワークロード管理システム\n\n\n一般的な企業では、複数のオペレーティングシステムをサポートする必要があります。 このプロジェクトのコアは、オープンソースプロジェクトと商用クラウド製品とその能力を活用することです。 \nTODO：ターゲットとなるユースケースと典型的なエンタープライズに結びつける\n\nサポートされる環境\n\n第一段階\n\n\n  Linuxやウェブサービスとそのバックエンドサービスの典型的なユースケース。オープンソースでのリリースにあたり、以下で説明するようにいくつかの選択肢について評価しています。\n\n\n第二段階\n\n\n  iOSやデスクトップクライアントのためのMac OSX。将来的にWindowsもサポートするかもしれません。Mac OSXスレーブへのジョブスケジューリングのためにJenkinsがサポートされる予定です。Jenkinsは多くのOSサポートがあるためここでは便利です。\n\n\nなぜJenkinsはどこにも使われないのですか？ Jenkinsは他の分野でも優れたサービスを提供していますが、アーキテクチャのスケーラビリティと全体的なパフォーマンスが制限されています。 さらに、Jenkinsクラスタの管理には、高い運用上のオーバーヘッドがあります。 Jenkinsを使用しないときのマイナス面は、既存のプラグインエコシステムにアクセスできないことです。\n\n選択基準\n\n\n  Yahooの外部で利用可能であること\n  セットアップのしやすさ\n  コミュニティの勢い（業界のイノベーション活用と我々のソリューションの将来性の裏付け\n  機能（半永続ストレージ、スケジューラオプションなど）\n  オンプレミスでもクラウド（AWSやGCP）でも動作\n  操作性\n\n\n候補\n\n\n  Kubernetes (GCPのコンテナエンジン含む)\n  Amazon ECS\n  Mesos\n  Docker Swarm\n\n\n当初の分析\n\n\n  Amazon ECSとKubernetesはセットアップが一番簡単でした。利用者がプラットフォームを簡単に試せるということです。どちらもクラウド上のプラットフォーム（KubernetesはGCPコンテナエンジンの場合）であるため、運用のオーバーヘッドもありません。\n  KubernetesはオンプレミスでもGCPでサポートされているインターフェースと同じものを利用可能にします。\n  ECSはAmazon限定でオンプレミスという選択肢がありません。\n  MesosはYahoo内部で利用されています。利用し始めるのは難しく、フレームワークの調査により多くの時間が必要です。\n  Docker Swarmも候補ですが、他の選択肢よりも成熟していません。今後の成長に注目です。\n\n\nCapabilities analysis requires learning the underlying systems to a certain degree.  The evaluation process includes an end to end integration to understand integration points as well as the strength and weaknesses of the system.  Kubernetes was chosen for the first end to end integration.\n\nTODO: add results of evaluations\n",
id: 20
});

index.add({
title: "What is Screwdriver?",
content: "What is Screwdriver?\n\nA collection of services that facilitate the workflow for continuous delivery pipelines.\n\n\n    \n        Secure Continuous Delivery\n        Screwdriver treats Continuous Delivery as a first-class citizen in your build pipeline.\n        Easily define the path that your code takes from Pull Request to Production.\n    \n    \n        \n    \n\n\n\n    \n        \n    \n    \n        Integrates with Daily Habits\n        Screwdriver ties directly into your DevOps daily habits.\n        It tests your pull requests, builds your merged commits, and deploys to your environments.\n        Define load tests, canary deployments, and multi-environment deployment pipelines with ease.\n    \n\n\n\n    \n        Pipeline as Code\n        Define your pipeline in a simple YAML file that lives beside your code.\n        There is no external configuration of your pipeline to deal with,\n        so you can review pipeline changes and roll them out with the rest of your codebase.\n    \n    \n        \n    \n\n\n\n    \n        \n    \n    \n        Runs Anywhere\n        Screwdriver's architecture uses pluggable components under the hood\n        to allow you to swap out the pieces that make sense for your infrastructure.\n        Swap in Postgres for the Datastore or Jenkins for the Executor.\n        You can even dynamically select an execution engine based on the needs of each pipeline.\n        For example, send golang builds to the kubernetes executor while your iOS builds go to a\n        Jenkins execution farm.\n    \n\n",
id: 21
});

index.add({
title: "Overall",
content: "Yaml Configuration\n\nThis is an interactive guide for exploring various important properties of the screwdriver.yaml configuration for projects.\n\nYou can access information about properties by hovering over the property name.\n\nNote: Parallel, series, and matrix have not been implemented yet. Everything will run in series by default.\n\n\n\n\nworkflow:\n    - publish\n\nshared:\n    environment:\n    NODE_ENV: test\n    settings:\n        email:\n    addresses: [test@email.com, test2@email.com]\n    statuses: [SUCCESS, FAILURE]\n    annotations:\n    beta.screwdriver.cd/executor: docker\njobs:\n    main:\n        image: node:&#123;&#123;NODE_VERSION&#125;&#125;\n        matrix:\n    NODE_VERSION: [4,5,6]\n        steps:\n    - init: npm install\n    - test: npm test\n    publish:\n    image: node:6\n    steps:\n        - publish: npm publish\n    deploy-west:\n    image: node:6\n    environment:\n        DEPLOY_ENV: west\n    steps:\n        - init: npm install\n        - publish: npm deploy\n    ...\n\n    \n        \n            Workflow\n            Defines the order of jobs that are executed for the project. All jobs referenced by the workflow must be defined in the jobs section.\n        \n        \n            Shared\n            Defines a global configuration that applies to all jobs. Shared configurations are merged with each job, but may be overridden by more specific configuration in a specific job.\n        \n        \n            Environment\n            A set of key/value pairs for environment variables that need to be set. Any configuration that is valid for a job configuration is valid in shared, but will be overridden by specific job configurations.\n        \n        \n            Settings\n            Configurable settings for any additional build plugins added to Screwdriver.cd.\n        \n        \n            Annotations\n            Annotations are an object containing key-value pairs; can be either pipeline or job-level specifications. In this case, the annotation `beta.screwdriver.cd/executor` is used to designate using Docker executor to run the pipeline.\n        \n        \n            Email\n            Emails addresses to send notifications to and statuses to send notifications for.\n        \n        \n            Jobs\n            A series of jobs that define the behavior of your builds.\n        \n        \n            Main\n            The only required job. This job is executed automatically whenever there is a code change.\n        \n        \n            Image\n            This defines the Docker image(s) used for the builds. This example shows a template replacement, where a variable is enclosed in curly braces, e.g. . This variable will be changed to the value(s) of the equivalent variable in the matrix setting, resulting in multiple builds running in parallel, each using one of those various images.\n        \n        \n            Matrix\n            This causes the builds for the job to execute on multiple images in parallel, when used a templated image configuration.\n        \n        \n            Steps\n            Defines the explicit list of commands that are executed in the build, just as if they were entered on the command line. Environment variables will be passed between steps, within the same job. Step definitions are required for all jobs. Step names cannot start with `sd-`, as those steps are reserved for Screwdriver steps. In essence, Screwdriver runs `/bin/sh` in your terminal then executes all the steps; in rare cases, different terminal/shell setups may have unexpected behavior.\n        \n    \n\n",
id: 22
});

index.add({
title: "Overall Architecture",
content: "Overall Architecture\n\nScrewdriver is a collection of services that facilitate the workflow for\nContinuous Delivery pipelines.\n\n\n\nWorkflow\n\n\n  \n    Commit new code\n\n    User starts a new build by one of the following operations:\n\n    \n      User pushes code to SCM\n      User opens a new pull request on SCM\n      User pushes code to SCM on an open pull request\n      User tells Screwdriver (via API or UI) to rebuild a given commit\n    \n  \n  \n    Notify Screwdriver\n\n    Signed webhooks notify\n Screwdriver’s API about the change.\n  \n  \n    Trigger execution engine\n\n    Screwdriver starts a job on the specified execution engine passing the\n user’s configuration and git information.\n  \n  \n    Build software\n\n    Screwdriver’s Launcher executes the commands specified in the user’s\n configuration after checking out the source code from git inside the\n desired container.\n  \n  \n    Publish artifacts (optional)\n\n    User can optionally push produced artifacts to respective artifact\n repositories (RPMs, Docker images, Node Modules, etc.).\n  \n  \n    Continue pipeline\n\n    On completion of the job, Screwdriver’s Launcher notifies the API and\n if there’s more in the pipeline, the API triggers the next job on the\n execution engine (GOTO:3).\n  \n\n\nComponents\n\nScrewdriver consists of five main components, the first three of which are\nbuilt/maintained by Screwdriver:\n\n\n  \n    REST API\n\n    RESTful interface for creating, monitoring, and interacting with pipelines.\n  \n  \n    Web UI\n\n    Human consumable interface for the REST API.\n  \n  \n    Launcher\n\n    Self-contained tool to clone, setup the environment, and execute the\n shell commands defined in your job.\n  \n  \n    Execution Engine\n\n    Pluggable build executor that supports executing commands inside of a\n container (e.g. Jenkins, Kubernetes, and Docker).\n  \n  \n    Datastore\n\n    Pluggable storage for keeping information about pipelines\n (e.g. Postgres, MySQL, and Sqlite).\n  \n\n",
id: 23
});

index.add({
title: "Screwdriverとは",
content: "Screwdriverとは\n\n継続的デリバリーパイプラインのワークフローを簡単にするサービス群\n\n\n    \n        安全な継続的デリバリー\n        Screwdriverはあなたのビルドパイプライン上で継続的デリバリーを第一級オブジェクトとして扱います。プルリクエストからプロダクションまでの流れを簡単に定義します。\n    \n    \n        \n    \n\n\n\n    \n        \n    \n    \n        日常業務との統合\n        ScrewdriverはDevOpsの日々の習慣と繋がります。pull requestをテストし、マージされたコミットをビルドし、各自の環境にデプロイします。負荷テストやカナリアデプロイ、複数環境へのデプロイパイプラインを簡単に定義できます。\n    \n\n\n\n    \n        パイプラインをコードで記述\n        シンプルなYAMLファイルをコードに追加することでパイプラインを定義できます。パイプラインを扱う他の設定は無いため、他のコードと合わせてパイプラインの変更をレビューした上で投入できます。\n    \n    \n        \n    \n\n\n\n    \n        \n    \n    \n        あらゆる環境で動作\n        Screwdriverのアーキテクチャは挿し替え可能なコンポーネントを使用し、利用者がそれらを自身のインフラに合ったものに差し替えることができます。データストアをPostgresに変更したり、実行エンジンをJenkinsに変更することができます。また、それぞれのパイプラインに応じて実行エンジンを選択することも可能です。例えば、Go言語のビルドにはkubernetesを使用し、iOSのビルドにはJenkinsを使用する、といったことが可能です。\n    \n\n",
id: 24
});

index.add({
title: "全体",
content: "Yaml設定\n\nここではscrewdriver.yamlの主要な設定についてインタラクティブに紹介します。\n\n各プロパティ名にマウスカーソルを乗せるとそれらの説明が表示されます。\n\n\n\n\nworkflow:\n    - publish\n    - parallel:\n        - series:\n            - deploy-east\n            - validate-east\n        - series:\n            - deploy-west\n            - validate-west\nshared:\n    environment:\n    NODE_ENV: test\n    settings:\n        email:\n    addresses: [test@email.com, test2@email.com]\n    statuses: [SUCCESS, FAILURE]\njobs:\n    main:\n        image: node:\n        matrix:\n    NODE_VERSION: [4,5,6]\n        steps:\n    - init: npm install\n    - test: npm test\n    publish:\n    image: node:6\n    steps:\n        - publish: npm publish\n    deploy-west:\n    image: node:6\n    environment:\n        DEPLOY_ENV: west\n    steps:\n        - init: npm install\n        - publish: npm deploy\n    ...\n\n    \n        \n            Workflow\n            パイプラインで実行されるジョブの順番を定義します。workflowで参照される全てのジョブはjosセクションに定義されている必要があります。\n            ジョブの実行は並列、順次、またはこの例のように両者の組み合わせも可能です。特別なキーワード parallel と series によりジョブのフローを定義できます。 デフォルトではworkflow内のジョブはmainジョブの成功後に順次実行されます。\n        \n        \n            Shared\n            全てのジョブの適用されるグローバル設定を定義します。Sharedの設定は各ジョブにマージされますが、それぞれのジョブで更に設定が行われている場合はその設定により上書きされます。\n        \n        \n            Environment\n            ビルドに必要な環境変数のキーと値の組み合わせです。ジョブに設定できる全ての設定はSharedにも設定できますが、ジョブの設定により上書きされます。\n        \n        \n            Settings\n            Configurable settings for any additional build plugins added to Screwdriver.cd.\n        \n        \n            Email\n            Emails addresses to send notifications to and statuses to send notifications for.\n        \n        \n            Jobs\n            ビルドの挙動を定義するジョブのリストです。\n        \n        \n            Main\n            唯一の必須ジョブです。このジョブはコードに変更が行われた際に自動的に実行されます。\n        \n        \n            Image\n            ビルドで利用されるDockerイメージを指定します。この例ではテンプレートを使用しており、のように波括弧で囲まれた変数が展開されます。 この変数はmatrixで指定されている値に変更され、それら複数のイメージを利用したビルドが並列に実行されます。\n        \n        \n            Matrix\n            image設定にテンプレートが利用されている場合、そのジョブのビルドが複数のイメージを利用して並列に実行されます。\n        \n        \n            Steps\n            コマンドラインで入力するように、ビルドで実行されるコマンドのリストを定義します。同じジョブ内では、環境変数はステップ間で受け渡されます。ステップの定義は全てのジョブに必須です。Screwdriverのステップとして予約語になっているため、ステップ名を'sd-'で始めることはできません。Screwdriverは'/bin/sh'をステップ実行のために使用するため、異なるターミナルやシェルを使用すると予期せぬ振る舞いをするかもしれません。\n        \n    \n\n",
id: 25
});

index.add({
title: "全体の構成",
content: "全体の構成\n\nScrewdriverは継続的デリバリーパイプラインのためのワークフローを簡単にするサービス群です。\n\n\n\nWorkflow\n\n\n  新しいコードのコミット下記のいずれかの操作により新しいビルドが開始されます。\n\n\n\n  SCMにコードをpush\n  SCM上で新しいpull requestを作成\n  pull request上に新しいコードをpush\n  ScrewdriverのAPIやUI上で、利用者がコミットのリビルドを指示\n\n\n\n  \n    Screwdriverへ通知\n\n    署名されたwebhooks がScrewdriverのAPIに対して変更を通知します。\n  \n  \n    ビルド実行エンジンが動作\n\n    Screwdriverに渡されたユーザーの設定やgitの情報を元に、指定されたビルド実行エンジンでビルドを開始します。\n  \n  \n    ソフトウェアのビルド\n\n    要求されたビルドコンテナ内でgitからソースコードをチェックアウトし、ユーザーの設定を元にScrewdriverのLauncherがコマンドを実行します。\n  \n  \n    アーティファクトのパブリッシュ (任意)\n\n    生成されたアーティファクトを各自のリポジトリに任意で送信できます。（RPM、Dockerイメージ、Nodeモジュールなど）\n  \n  \n    パイプラインの続行\n\n    ジョブの完了後にScrewdriverのLauncherがAPIに通知し、後続のジョブがあればAPIにより次のジョブがビルド実行エンジンで開始されます(3へ)。\n  \n\n\nコンポーネント\n\nScrewdriverには5つの主要コンポーネントがあり、最初の3つはScrewdriverによりビルド・メンテナンスされています。\n\n\n  REST API\n  パイプラインの生成、監視、操作のためのRESTfulインターフェース\n  Web UI\n  人が扱いやすいREST APIへのインターフェース\n  Launcher\n  ソースコードの取得や環境のセットアップ、各ジョブで定義されたコマンドの実行を行う自己完結のツール\n  実行エンジン\n  コンテナの中でコマンドを実行するための挿し替え可能なビルド実行エンジン(Jenkins, KubernetesやDockerなど)\n  データストア\n  パイプラインについての情報を保存する挿し替え可能なストレージ(Postgres, MySQLやSqliteなど)\n\n",
id: 26
});

index.add({
title: "ホーム",
content: "\n    \n    Screwdriverにようこそ\n    ドキュメントは3つの異なるセクションに分かれています\n\n\n\n    \n        クラスター管理\n        Screwdriverのクラスターを管理する方法についてはクラスター管理セクションをご覧ください。\n    \n    \n        ユーザーガイド\n        ビルドの実行にScrewdriverを利用したい場合はユーザーガイドをご覧ください。\n    \n    \n        概要\n        Screwdriverについてのその他一般的な情報については概要セクションをご覧ください。.\n    \n\n\n\n    \n        初めてScrewdriverを利用する場合、まずはドメインモデルとYAML設定を読み、Screwdriverの各種概念を理解した上でそれらがどのように繋がっているかを理解することから始めてみましょう。\n        クイックスタートの例より様々な言語のビルドを実際に試すことができます。\n    \n\n",
id: 27
});

index.add({
title: "Home",
content: "\n    \n    Welcome to Screwdriver!\n    We've split documentation into 3 distinct sections:\n\n\n\n    \n        Cluster Management\n        To find more information about managing your own Screwdriver cluster,\n        visit the Cluster Management section.\n    \n    \n        User Guide\n        If you'd like to use Screwdriver to run a build, visit our User Guide.\n    \n    \n        About\n        To learn more about Screwdriver in general, visit the About section.\n    \n\n\n\n    \n        If you are new to Screwdriver, we suggest you start by reading through the Domain model and YAML configuration to get an idea of different concepts in Screwdriver and how they tie together.\n\n        To see some working examples, you can try out our quickstart examples with different languages to choose from.\n    \n\n",
id: 28
});

index.add({
title: "Kubernetes",
content: "Setting Up a Screwdriver Cluster on AWS using Kubernetes\nWe’ll go over how to set up a Screwdriver cluster on AWS using Kubernetes, Github, and a Postgres database. You can setup a Screwdriver cluster using Kubernetes.\n\nScrewdriver cluster\nA Screwdriver cluster consists of a Kubernetes cluster running the Screwdriver API. The Screwdriver API modifies Screwdriver tables in AWS RDS.\n\n\n\nPrerequisites\n\n  kubectl\n  an AWS account\n  AWS CLI\n\n\nCreate your Kubernetes cluster\nFollow instructions at Running Kubernetes on AWS EC2.\n\nSetup Screwdriver secrets\nAfter creating your Kubernetes cluster, you’ll need to populate it with some secrets that will give you access to your database and Github.\nA Secret is an object that contains a small amount of sensitive data such as a password, token, or key.\n\nHere’s a list of secrets we will need:\n\n\n  \n    \n      Secret Key\n      Description\n    \n  \n  \n    \n      SECRET_JWT_PRIVATE_KEY\n      A private key used for signing JWT tokens\n    \n    \n      SECRET_JWT_PUBLIC_KEY\n      A public key used for signing JWT tokens\n    \n    \n      DATASTORE_SEQUELIZE_DATABASE\n      SQL database name\n    \n    \n      DATASTORE_SEQUELIZE_USERNAME\n      SQL database username\n    \n    \n      DATASTORE_SEQUELIZE_PASSWORD\n      SQL database password\n    \n    \n      SECRET_OAUTH_CLIENT_ID\n      The client ID used for OAuth with Github\n    \n    \n      SECRET_OAUTH_CLIENT_SECRET\n      The client secret used for OAuth with github\n    \n    \n      WEBHOOK_GITHUB_SECRET\n      Secret to add to GitHub webhooks so that we can validate them\n    \n    \n      SECRET_PASSWORD\n      A password used for encrypting session, and OAuth data. Can be anything. Needs to be minimum 32 characters\n    \n    \n      K8S_TOKEN\n      Your Kubernetes \n    \n  \n\n\nGenerate JWT keys\nTo generate a jwtprivatekey, run:\n\n$ openssl genrsa -out jwt.pem 2048\n\nTo generate a jwtpublickey, run:\n\n$ openssl rsa -in jwt.pem -pubout -out jwt.pub\n\nGet your OAuth Client ID and Secret\n\n\n  \n    Navigate to the OAuth applications page.\n  \n  \n    Click Register a new application.\n  \n  \n    Fill out the information and click Register application.\n  \n\n\n\n\nYou should see a Client ID and Client Secret, which will be used for your oauthclientid and oauthclientsecret, respectively.\n\nCreate a datastore\nTo get your SQL datastore secrets, set up a datastore with AWS RDS.\n\n\n  \n    Navigate to AWS RDS. Click on Launch a DB Instance.\n\n    \n  \n  \n    Select the PostgreSQL tab. Click Select.\n\n    \n  \n  \n    Choose an environment (Production or Dev/Test) and click Next Step.\n\n    \n  \n  \n    Fill out the DB Instance Identifier (DATASTORE_SEQUELIZE_DATABASE), Master Username (DATASTORE_SEQUELIZE_USERNAME), Master Password (DATASTORE_SEQUELIZE_PASSWORD), and Confirm Password. Click Next Step.\n\n    \n  \n  \n    Add a Database Name. Make sure the VPC Security Group chosen gives inbound access to all IPs. Click Launch DB Instance.\n\n    \n  \n  \n    Click View Your DB Instances. Click on the small triangle next to the Engine column on your DB instance row to open up the details. Your endpoint will be your Database host name.\n\n    \n  \n\n\nBase64 encode your secrets\nEach secret must be base64 encoded. You must base64 encode each of your secrets:\n\n$ echo -n \"somejwtprivatekey\" | base64\nc29tZWp3dHByaXZhdGVrZXk=\n$ echo -n \"anypassword\" | base64\nYW55cGFzc3dvcmQ=\n\n\n\nSetting up secrets in Kubernetes\nTo create secrets in Kubernetes, create a secret.yaml file and populate it with your secrets. These secrets will be used in your Kubernetes deployment.yaml file.\n\nIt should look similar to the following:\n\napiVersion: v1\nkind: Secret\nmetadata:\n  name: screwdriver-api-secrets\ntype: Opaque\ndata:\n  # make sure the values are all base64 encoded\n  dbhost: ZGJob3N0bmFtZWhlcmU=\n  dbusername: bXlkYXRhYmFzZQ==\n  dbpassword: c29tZXBhc3N3b3Jk\n  password: YW55cGFzc3dvcmQ=\n  oauthclientid: c29tZWNsaWVudGlk\n  oauthclientsecret: c29tZWNsaWVudHNlY3JldA==\n  jwtprivatekey: c29tZWp3dHByaXZhdGVrZXk=\n  jwtpublickey: c29tZWp3dHB1YmxpY2tleQ==\n  githubsecret: c29tZWdpdGh1YnNlY3JldA==\n\n\n\nCreate the secrets using kubectl create:\n\n$ kubectl create -f ./secret.yaml\n\n\n\nAdditional environment variables\nOther environment variables can also be customized for Screwdriver. For a full list, see the custom-environment-variables.yaml file.\n\nDeploy Screwdriver\nYou can check out the api.yaml in the Screwdriver config examples repo for example service and deployment definitions to run the Screwdriver API.\n\nCreate a Service\nA Kubernetes Service is an abstraction which defines a set of Pods and is assigned a unique IP address which persists.\nFollow instructions in Creating a Service to set up your service.yaml.\n\nIt should look like the Service in api.yaml.\n\nTo create your service, run the kubectl create command on your service.yaml file:\n$ kubectl create -f service.yaml\n\n\n\nGet your Kubernetes token name\nKubernetes actually sets up your Kubernetes token by default. You will need this for your deployment.yaml.\nYou can use kubectl to see your Kubernetes secrets.\n\nGet the &lt;DEFAULT_TOKEN_NAME&gt;, by running:\n\n$ kubectl get secrets\n\nNAME                      TYPE                                  DATA      AGE\ndefault-token-abc55       kubernetes.io/service-account-token   3         50d\n\n\n\nThe &lt;DEFAULT_TOKEN_NAME&gt; will be listed under Name when the Type is kubernetes.io/service-account-token.\n\nGet your URI\nYou will need to get the Load Balancer Ingress to set your URI in your deployment.yaml.\n\nGet the LoadBalancer Ingress, by running:\n\n$ kubectl describe services sdapi\n\n\n\nCreate a Deployment\nA Deployment makes sure a specified number of pod “replicas” are running at any one time. If there are too many, it will kill some; if there are too few, it will start more. Follow instructions on the Deploying Applications page to create your deployment.yaml.\n\nIt should look like the Deployment in api.yaml.\n\nDeploy\nFor a fresh deployment, run the kubectl create command on your deployment.yaml file:\n\n$ kubectl create -f deployment.yaml\n\n\n\nView your pods\nA Kubernetes pod is a group of containers, tied together for the purposes of administration and networking.\n\nTo view the pod created by the deployment, run:\n\n$ kubectl get pods\n\n\n\nTo view the stdout / stderr from a pod, run:\n\n$ kubectl logs &lt;POD-NAME&gt;\n\n\n\nUpdate your OAuth Application\nYou will need to navigate back to your original OAuth Application that you used for your OAuth Client ID and Secret to update the URLs.\n\n\n  \n    Navigate to the OAuth applications page.\n  \n  \n    Click on the application you created to get your OAuth Client ID and Secret.\n  \n  \n    Fill out the Homepage URL and Authorization callback URL with your LoadBalancer Ingress.\n  \n\n",
id: 29
});

index.add({
title: "Kubernetes",
content: "Kubernetesを利用してAWS上にScrewdriverのクラスタを構築\n\nWe’ll go over how to set up a Screwdriver cluster on AWS using Kubernetes, Github, and a Postgres database. You can setup a Screwdriver cluster using Kubernetes.\n\nScrewdriverクラスタ\n\nA Screwdriver cluster consists of a Kubernetes cluster running the Screwdriver API. The Screwdriver API modifies Screwdriver tables in AWS RDS.\n\n\n\n必要なもの\n\n\n  kubectl\n  AWSアカウント\n  AWS CLI\n\n\nKubernetesクラスタの作成\n\nFollow instructions at Running Kubernetes on AWS EC2.\n\nSetup Screwdriver secrets\n\nAfter creating your Kubernetes cluster, you’ll need to populate it with some secrets that will give you access to your database and Github.\nA Secret is an object that contains a small amount of sensitive data such as a password, token, or key.\n\nHere’s a list of secrets we will need:\n\n\n  \n    \n      Secret Key\n      説明\n    \n  \n  \n    \n      SECRET_JWT_PRIVATE_KEY\n      A private key used for signing JWT tokens\n    \n    \n      SECRET_JWT_PUBLIC_KEY\n      A public key used for signing JWT tokens\n    \n    \n      DATASTORE_SEQUELIZE_DATABASE\n      SQL database name\n    \n    \n      DATASTORE_SEQUELIZE_USERNAME\n      SQL database username\n    \n    \n      DATASTORE_SEQUELIZE_PASSWORD\n      SQL database password\n    \n    \n      SECRET_OAUTH_CLIENT_ID\n      GithubのOAuthで使用するClient ID\n    \n    \n      SECRET_OAUTH_CLIENT_SECRET\n      GithubのOAuthで使用するClient Secret\n    \n    \n      WEBHOOK_GITHUB_SECRET\n      GitHub webhookに設定して正当性を検証するためのパスワード\n    \n    \n      SECRET_PASSWORD\n      セッションとOAuthデータを暗号化するためのパスワード。中身は何でもよいですが32文字以上である必要があります。\n    \n    \n      K8S_TOKEN\n      用意したKubernetesの\n    \n  \n\n\nGenerate JWT keys\n\njwtprivatekeyを生成するには次のコマンドを実行します。\n\n$ openssl genrsa -out jwt.pem 2048\n\njwtpublickeyを生成するには次のコマンドを実行します。\n\n$ openssl rsa -in jwt.pem -pubout -out jwt.pub\n\nOAuth Client IDとSecretの取得\n\n\n  OAuth applicationsページを開きます。\n  Register a new applicationをクリックします。\n  情報を入力しRegister applicationをクリックします。\n\n\n\n\nClient IDとClient Secretが表示され、それぞれoauthclientid、oauthclientsecretとなります。\n\nCreate a datastore\n\nTo get your SQL datastore secrets, set up a datastore with AWS RDS.\n\n\n  Navigate to AWS RDS. Click on Launch a DB Instance.\n  Select the PostgreSQL tab. Click Select.\n  Choose an environment (Production or Dev/Test) and click Next Step.\n  Fill out the DB Instance Identifier (DATASTORE_SEQUELIZE_DATABASE), Master Username (DATASTORE_SEQUELIZE_USERNAME), Master Password (DATASTORE_SEQUELIZE_PASSWORD), and Confirm Password. Click Next Step.\n  Add a Database Name. Make sure the VPC Security Group chosen gives inbound access to all IPs. Click Launch DB Instance.\n  Click View Your DB Instances. Click on the small triangle next to the Engine column on your DB instance row to open up the details. Your endpoint will be your Database host name.\n\n\n秘密情報のBase64エンコード\n\n各秘密情報はbase64エンコードされている必要があるので、それぞれをbase64エンコードします。\n\n$ echo -n \"somejwtprivatekey\" | base64\nc29tZWp3dHByaXZhdGVrZXk=\n$ echo -n \"anypassword\" | base64\nYW55cGFzc3dvcmQ=\n\n\n\nKubernetesにsecretを設定\n\nKubernetesにsecretを作成するには、秘密情報を入力したsecret.yamlを作成します。入力した情報はKubernetesのdeployment.yamlファイルで使用されます。\n\n下記のような内容になるはずです。\n\napiVersion: v1\nkind: Secret\nmetadata:\n  name: screwdriver-api-secrets\ntype: Opaque\ndata:\n  # make sure the values are all base64 encoded\n  dbhost: ZGJob3N0bmFtZWhlcmU=\n  dbusername: bXlkYXRhYmFzZQ==\n  dbpassword: c29tZXBhc3N3b3Jk\n  password: YW55cGFzc3dvcmQ=\n  oauthclientid: c29tZWNsaWVudGlk\n  oauthclientsecret: c29tZWNsaWVudHNlY3JldA==\n  jwtprivatekey: c29tZWp3dHByaXZhdGVrZXk=\n  jwtpublickey: c29tZWp3dHB1YmxpY2tleQ==\n  githubsecret: c29tZWdpdGh1YnNlY3JldA==\n\n\n\nkubectl createを使用してsecretを作成します。\n\n$ kubectl create -f ./secret.yaml\n\n\n\n追加の環境変数\n\nScrewdriver向けに他の環境変数もカスタマイズできます。全てのリストについてはcustom-environment-variables.yamlファイルをご覧ください。\n\nScrewdriverのデプロイ\n\nYou can check out the api.yaml in the Screwdriver config examples repo for example service and deployment definitions to run the Screwdriver API.\n\nServiceの作成\n\nKubernetesのServiceは一連のPodやユニークなIP割り振りなどが定義されたものという概念です。\nCreating a Serviceページの手順でservice.yamlを準備します。\n\napi.yamlのような構成になるはずです。\n\nServiceを作成するにはservice.yamlファイルに対してkubectl createを実行します。\n\n$ kubectl create -f service.yaml\n\n\n\nKubernetesトークン名の取得\n\nKubernetes actually sets up your Kubernetes token by default. You will need this for your deployment.yaml.\nYou can use kubectl to see your Kubernetes secrets.\n\nGet the &lt;DEFAULT_TOKEN_NAME&gt;, by running:\n\n$ kubectl get secrets\nNAME                      TYPE                                  DATA      AGE\ndefault-token-abc55       kubernetes.io/service-account-token   3         50d\n\n\n\nThe &lt;DEFAULT_TOKEN_NAME&gt; will be listed under Name when the Type is kubernetes.io/service-account-token.\n\nURIの取得\n\ndeployment.yaml内のURIを設定するためにLoad Balancer Ingressを取得する必要があります。\n\n次を実行することでLoadBalancer Ingressが取得できます。\n\n$ kubectl describe services sdapi\n\n\n\nDeploymentの作成\n\nA Deployment makes sure a specified number of pod “replicas” are running at any one time. If there are too many, it will kill some; if there are too few, it will start more. Follow instructions on the Deploying Applications page to create your deployment.yaml.\n\nIt should look like the Deployment in api.yaml.\n\nデプロイ\n\nFor a fresh deployment, run the kubectl create command on your deployment.yaml file:\n\n$ kubectl create -f deployment.yaml\n\n\n\nPodsの確認\n\nKubernetesのpodはコンテナの集まりで、管理とネットワークの目的でお互いに結びついています。\n\ndeploymentによって作成されたpodを確認するには、以下を実行します。\n\n$ kubectl get pods\n\n\n\nPodからの標準出力とエラーを確認するには以下を実行します。\n\n$ kubectl logs &lt;POD-NAME&gt;\n\n\n\nOAuth Applicationの更新\n\nYou will need to navigate back to your original OAuth Application that you used for your OAuth Client ID and Secret to update the URLs.\n\n\n  OAuth applicationsページを開きます。\n  作成したアプリケーションをクリックし、OAuth Client IDとSecretを取得します。\n  Homepage URLとAuthorization callback URLをご使用のLoadBalancer Ingressで埋めてください。\n\n",
id: 30
});

index.add({
title: null,
content: "var index = lunr(function () {\n  this.field('title')\n  this.field('content', {boost: 10})\n  this.ref('id')\n});\n{% assign count = 0 %}{% for page in site.pages %}\nindex.add({\ntitle: {{page.title | jsonify}},\ncontent: {{page.content | strip_html | jsonify}},\nid: {{count}}\n});{% assign count = count | plus: 1 %}\n{% endfor %}\n\nvar store = [{% for page in site.pages %}{\n  \"title\": {{page.title | jsonify}},\n  \"url\": {{ page.url | jsonify }},\n  \"summary\": {{ page.content | strip_html | truncatewords: 20 | jsonify }},\n  \"menu\": \"{{page.menu}}\"\n}{% unless forloop.last %},{% endunless %}{% endfor %}]\nconsole.log(store[1].title);\nconsole.log(store[1].summary);\n// builds search\n\n$(document).ready(function() {\n  $('#search').on('keyup', function () {\n    var resultdiv = $('#results');\n    var res_count = 0;\n    // Get query\n    var query = $(this).val();\n    // Search for it\n    var result = index.search(query);\n    // Show results\n    resultdiv.empty();\n    // Loop through, match, and add results\n    for (var item in result) {\n      var ref = result[item].ref;\n      if(store[ref].menu == page_menu && store[ref].url != '/404.html') {\n        var searchitem = ''+store[ref].title+''+store[ref].summary+'';\n        resultdiv.append(searchitem);\n        res_count = res_count + 1;\n      }\n    }\n    if (res_count == 0) {\n        var notfound = 'No results found';\n        resultdiv.append(notfound);\n    }\n  });\n});\n",
id: 31
});

index.add({
title: "Metadata",
content: "# Metadata\n\n## What is Metadata?\n\nMetadata is a structured key/value storage of relevant information about a [build](../../about/appendix/domain#build). Metadata will be shared with subsequent builds in the same [workflow](../../about/appendix/domain#workflow). It can be updated or retrieved throughout the build by using the built-in [meta CLI](https://github.com/screwdriver-cd/meta-cli) in the [steps](../../about/appendix/domain#step).\n\n## Manipulating Metadata\n\nScrewdriver provides the shell command `meta get` to extract information from the meta store and `meta set` to save information to the meta store.\n\nExample:\n```bash\n$ meta set example.coverage 99.95\n$ meta get example.coverage\n99.95\n$ meta get example\n{\"coverage\":99.95}\n```\n\nExample:\n```bash\n$ meta set foo[2].bar[1] baz\n$ meta get foo\n[null,null,{\"bar\":[null,\"baz\"]}]\n```\n",
id: 32
});

index.add({
title: "Metadata",
content: "# Metadata\n\n## What is Metadata?\n\nMetadata is a structured key/value storage of relevant information about a [build](../../about/appendix/domain#build). Metadata will be shared with subsequent builds in the same [workflow](../../about/appendix/domain#workflow). It can be updated or retrieved throughout the build by using the built-in [meta CLI](https://github.com/screwdriver-cd/meta-cli) in the [steps](../../about/appendix/domain#step).\n\n## Manipulating Metadata\n\nScrewdriver provides the shell command `meta get` to extract information from the meta store and `meta set` to save information to the meta store.\n\nExample:\n```bash\n$ meta set example.coverage 99.95\n$ meta get example.coverage\n99.95\n$ meta get example\n{\"coverage\":99.95}\n```\n\nExample:\n```bash\n$ meta set foo[2].bar[1] baz\n$ meta get foo\n[null,null,{\"bar\":[null,\"baz\"]}]\n```\n",
id: 33
});

index.add({
title: "Quickstart",
content: "# Getting Started with Screwdriver\n\nThis page will cover how to build and deploy a sample app with Screwdriver in minutes. In this example, we are using the SCM provider Github.\n\n## Requirements\n- Github account\n\n## Set Up\nFirst, fork and clone a sample repository into your local development environment and cd into the project directory. We will cover the generic quickstart in this example.\n\n- [generic](https://github.com/screwdriver-cd-test/quickstart-generic)*\n- [Golang](https://github.com/screwdriver-cd-test/quickstart-golang)\n- [Nodejs](https://github.com/screwdriver-cd-test/quickstart-nodejs)\n- [Ruby](https://github.com/screwdriver-cd-test/quickstart-ruby)\n\n```bash\n$ git clone git@github.com:/quickstart-generic.git\n$ cd quickstart-generic/\n```\n\n*For applications that are better suited to Makefiles and small scripts, we recommend referencing the generic `screwdriver.yaml`.*\n\n## Developing the App\n\nNow that we’ve setup our app, we can start developing. This app demonstrates how to run a `Makefile` and bash script (`my_script.sh`) in your Screwdriver build.\n\n### screwdriver.yaml\n\nThe `screwdriver.yaml` is the only config file you need for using Screwdriver. In it, you will define all your steps needed to successfully develop, build and deploy your application.\n\n#### Workflow\n\nThe `workflow` describes the order that the jobs execute. The \"main\" job, which is created by default, is always\nexecuted first, followed by jobs listed in this workflow block.\n\nHere, we have defined a job named \"second_job\", which\nwill run after the \"main\" job.\n\n```yaml\n---\n# Workflow list definition\nworkflow:\n  - second_job\n```\n\n#### Shared\nThe `shared` section is where you would define any attributes that all your jobs will inherit.\n\nIn our example, we state that all our jobs will run in the same Docker container image \"buildpack-deps\". The `image` is usually defined in the form of \"repo_name\". Alternatively, you can define the image as \"repo_name:tag_label\", where \"tag_label\" is a version. See the [Docker documentation](https://docs.docker.com/engine/reference/commandline/pull/#pull-an-image-from-docker-hub) for more information.\n\n```yaml\n# Shared definition block\nshared:\n  # Source: https://hub.docker.com/r/library/buildpack-deps/\n  image: buildpack-deps\n```\n\n#### Jobs\nThe `jobs` section is where all the tasks (or `steps`) that each job will execute is defined. All pipelines have \"main\" implicitly defined. The definitions in your screwdriver.yaml file will override the implied defaults.\n\n### Steps\nThe `steps` section contains a list of commands to execute.\nEach step takes the form \"step_name: command_to_run\". The \"step_name\" is a convenient label to reference it by. The\n\"command_to_run\" is the single command that is executed during this step. Step names cannot start with `sd-`, as those steps are reserved for Screwdriver steps. Environment variables will be passed between steps, within the same job. In essence, Screwdriver runs `/bin/sh` in your terminal then executes all the steps; in rare cases, different terminal/shell setups may have unexpected behavior.\n\nIn our example, our \"main\" job executes a simple piece of inline bash code. The first step (`export`) exports an environment variable, `GREETING=\"Hello, world!\"`. The second step (`hello`) echoes the environment variable from the first step. The third step uses [metadata](./configuration/metadata), a structured key/value storage of relevant information about a build, to set an arbitrary key in the \"main\" job and get it in the \"second_job\".\n\nWe also define another job called \"second_job\". In this job, we intend on running a different set of commands. The \"make_target\" step calls a Makefile target to perform some set of actions. This is incredibly useful when you need to perform a multi-line command.\nThe \"run_arbitrary_script\" executes a script. This is an alternative to a Makefile target where you want to run a series of commands related to this step.\n\n```yaml\n# Job definition block\n# \"main\" is a default job that all pipelines have\njobs:\n  main:\n    # Steps definition block.\n    steps:\n      - export: export GREETING=\"Hello, world!\"\n      - hello: echo $GREETING\n      - set-metadata: meta set example.coverage 99.95\n  second_job:\n    steps:\n      - make_target: make greetings\n      - get-metadata: meta get example\n      - run_arbitrary_script: ./my_script.sh\n```\n\nNow that we have a working repository, let's head over to the Screwdriver UI to build and deploy an app. (For more information on Screwdriver YAMLs, see the [configuration](./configuration) page.)\n\n## Building with Screwdriver\n\nIn order to use Screwdriver, you will need to login to Screwdriver using Github, set up your pipeline, and start a build.\n\n\n### Create a New Pipeline\n\n1. Click on the Create icon. (You will be redirected to login if you have not already.)\n\n1. _Click Login with SCM Provider._\n\n1. _You will be asked to give Screwdriver access to your repositories. Choose appropriately and click Authorize._\n\n1. Enter your repository link into the field. SSH or HTTPS link is fine, with `#` immediately after (ex: `git@github.com:screwdriver-cd/guide.git#test`). If no `BRANCH_NAME` is provided, it will default to the `master` branch.\nClick Use this repository to confirm and then click Create Pipeline.\n\n### Start Your First Build\nNow that you've created a pipeline, you should be directed to your new pipeline page. Click the Start button to start your build.\n\n\n## Congratulations! You just built and ran your first app using Screwdriver!\n",
id: 34
});

index.add({
title: "クイックスタート",
content: "# Getting Started with Screwdriver\n\nこのページでは、Screwdriverを利用して簡単なアプリケーションが短時間でどのようにビルド・デプロイされるか説明します。このページの例ではSCMプロバイダとしてGithubを利用します。\n\n## 必要なもの\n\n- Githubアカウント\n\n## セットアップ\n\nまず最初に、サンプルリポジトリを開発環境にcloneし、そのプロジェクトディレクトリにcdします。この先の例ではgenericについて説明します。\n\n- [generic](https://github.com/screwdriver-cd-test/quickstart-generic)*\n- [Golang](https://github.com/screwdriver-cd-test/quickstart-golang)\n- [Nodejs](https://github.com/screwdriver-cd-test/quickstart-nodejs)\n- [Ruby](https://github.com/screwdriver-cd-test/quickstart-ruby)\n\n```bash\n$ git clone git@github.com:/quickstart-generic.git\n$ cd quickstart-generic/\n```\n\n*Makefileや小さなスクリプトの場合はgenericの`screwdriver.yaml`を参照することをお勧めします。\n\n## アプリケーションの開発\n\nアプリケーションがセットアップできたので開発を始めることができます。このアプリケーションにより、Screwdriverのビルド内でどのように`Makefile`とbashスクリプト(`my_script.sh`)が実行されるかを確認できます。\n\n### screwdriver.yaml\n\n`screwdriver.yaml`はScrewdriverを利用する際に必要となる唯一の設定ファイルです。このファイルにはアプリケーションの開発、ビルド、デプロイに必要なすべてのステップを定義します。\n\n#### Workflow\n\n`workflow`はジョブ実行の順番を表します。デフォルトで作成される \"main\" ジョブは常に最初に実行され、その後このworkflowブロックにリストアップされたジョブが実行されます。\n\nここでは \"main\" ジョブの後に実行される \"second_job\" という名前のジョブを定義しています。\n\n```yaml\n---\n# Workflow list definition\nworkflow:\n  - second_job\n```\n\n#### Shared\n\n`shared`セクションは、すべてのジョブに継承される属性を定義する場所です。\n\n今回の例では、全てのジョブは同じ\"buildpack-deps\"というDockerコンテナで実行されます。`image`は\"repo*name\"の形で通常定義されます。または、\"repo*name:tag*_name:tag*label\"_label\"の形で定義することができ、\"tag_label\"にはimageのバージョンが入ります。詳しくは[Dockerのドキュメント](https://docs.docker.com/engine/reference/commandline/pull/#pull-an-image-from-docker-hub)をご覧ください。\n\n```yaml\n# Shared definition block\nshared:\n  # Source: https://hub.docker.com/r/library/buildpack-deps/\n  image: buildpack-deps\n```\n\n#### Jobs\n\n`jobs` セクションは、各ジョブで実行されるすべてのタスク（または`steps`）が定義される場所です。すべてのパイプラインにおいて、暗黙的に定義された\"main\"が実行されます。screwdriver.yamlファイルの定義は、暗黙のデフォルトを上書きします。\n\n### Steps\n\n`steps`セクションは、実行されるコマンドのリストが定義される場所です\n。それぞれのステップは\"step*name: command*to*run\"の形で定義します。\"step*name\"は自身を参照するわかりやすいラベルです。\n\"command*to*run\"はこのステップで実行される1つのコマンドです。ステップの名前は頭に`sd-`がつくものは設定できません。これは、Screwdriverのステップとして予約語になっているからです。同じジョブであれば、環境変数はステップ間で受け渡しすることができます。基本的に、Screwdriverはターミナルで`/bin/sh`を実行します。稀に、異なるターミナルやシェルを使用する場合、予期せぬ振る舞いをする可能性があります。\n\n例えば、 \"main\" ジョブは簡単な1行のシェルコマンドを実行する例を示します。最初のステップ(`export`)は環境変数 `GREETING=\"Hello, world!\"`をセットしています。2番目のステップ(`hello`)では、1ステップ目でセットした環境変数を出力しています。\n\nまた、 \"second*job\" という別のジョブを定義します。このジョブでは別のコマンドセットを実行するつもりです。 \"make*target\"_target\" ステップではMakefileターゲットを呼び、いくつかの処理を実行させます。これは複数行のコマンドを実行する必要がある場合に非常に便利です。 \n\"run*arbitrary*script\"  ステップではスクリプトを実行します。これは続きのステップであり、Makefileターゲットを呼ぶ以外の方法で複数のコマンドを実行できる代替案です。\n\n```yaml\n# Job definition block\n# \"main\" is a default job that all pipelines have\njobs:\n  main:\n    # Steps definition block.\n    steps:\n      - export: export GREETING=\"Hello, world!\"\n      - hello: echo $GREETING\n  second_job:\n    steps:\n      - make_target: make greetings\n      - run_arbitrary_script: ./my_script.sh\n```\n\n作業用リポジトリができたのでScrewdriverのUIよりアプリケーションをビルド・デプロイしてみましょう。（ScrewdriverのYAMLについて詳しくは[設定](./configuration)ページをご覧ください。）\n\n## Screwdriverによるビルド\n\nScrewdriverを利用するには、Githubを利用してScrewdriverにログインし、パイプラインをセットアップし、ビルドを開始する必要があります。\n\n### 新しいパイプラインを作成\n\n1. Createアイコンをクリックします。（未ログインの場合はログインページにリダイレクトします）\n2. *\"Login with SCM Provider\" ボタンを押します。*\n3. *あなたのリポジトリへのアクセス権をScrewdriverに与えてよいか確認されます。適切に選択し、Authorizeボタンをクリックします。*\n4. ビルド対象リポジトリのリンクを入力します。SSHかHTTPSリンクの後に`#`を付加します(例: `git@github.com:screwdriver-cd/guide.git#test`)。`BRANCH_NAME`が指定されない場合、デフォルトとして`master`ブランチが指定されます。 \"Use this repository\" をクリックし、 ”Create Pipeline\" をクリックします。\n\n### はじめてのビルドを開始\n\nパイプラインが作成されたら、新しいパイプラインのページに移動します。スタートボタンをクリックしてビルドを開始しましょう。\n\n## おめでとう！Screwdriverを利用して最初のアプリケーションをビルド・実行できました🎉\n",
id: 35
});

index.add({
title: "Running Locally",
content: "# Running Locally\nYou can run Screwdriver locally by using our Screwdriver-in-a-box tool.\n\n## SD-in-a-Box\nThis handy feature will bring up an entire Screwdriver instance (UI, API, and log store) locally for you to play with.\n\n### Requires:\n - Mac OSX 10.10+\n - [Docker for Mac][docker]\n - [Docker Compose 1.8.1+][docker-compose]\n - Python 2.6+\n\nRun the below command in your terminal to bring up a Screwdriver cluster locally.\n\n```bash\n$ python <(curl https://raw.githubusercontent.com/screwdriver-cd/screwdriver/master/in-a-box.py)\n```\n\nYou will be prompted to enter your Client ID and Client Secret. Afterwards, type `y` to launch Screwdriver!\n\n![SD-in-a-box](./assets/sd-in-a-box.png)\n\n[docker]: https://www.docker.com/products/docker\n[docker-compose]: https://www.docker.com/products/docker-compose\n\n## Configuring SD-in-a-Box\n\nSD-in-a-box was intended to be an easy way to run a Screwdriver cluster locally on your development machine so you can demo its features first-hand.\n\n### Custom Docker Images\n\nSince it's powered by Docker, you can determine which images to use for it. SD-in-a-Box (and Screwdriver as a whole) uses the following Docker images:\n\n* [screwdrivercd/screwdriver](https://hub.docker.com/r/screwdrivercd/screwdriver) - API. The main engine of the CI/CD cluster.\n* [screwdrivercd/ui](https://hub.docker.com/r/screwdrivercd/ui) - UI. To pleasantly interact with Screwdriver.\n* [screwdrivercd/store](https://hub.docker.com/r/screwdrivercd/store) - Artifact repository. Responsible for artifacts like build logs & templates\n* [screwdrivercd/launcher](https://hub.docker.com/r/screwdrivercd/launcher/tags/) - Worker component that executes the build. You *cannot* change the image. You can only specify a specific tag to use.\n\nHere is a snippet of the `docker-compose.yml` file\n\n```\nversion: '2'\nservices:\n  api:\n    image: screwdrivercd/screwdriver:stable\n    . . .\n  ui:\n    image: screwdrivercd/ui:stable\n    . . .\n  store:\n    image: screwdrivercd/store:stable\n    . . .\n```\n\nYou can make a local Docker image to use instead of one of these.\n\nTo start up the SD-in-a-Box, execute the following command\n\n```bash\n$ docker-compose -p screwdriver up\n```\n\n### Volume-Mounted Source Code\n\nYou can choose to replace a component with a local copy. This is incredibly helpful if you're trying to implement an update to a service and want to see how it impacts the entire cluster.\n\nModify the `docker-compose.yaml`, targeting the component you would like to replace. In the following snippet, we replace the API with a local source.\n\n```\nservices:\n  api:\n    # this \"build\" stanza replaces the default \"image\" setting\n    build:\n      context: ./relative/path/to/api_source\n      dockerfile: Dockerfile.local\n  ui:\n    . . .\n  store:\n    . . .\n```\n\nTo set your update, you'll need to rebuild the docker-compose services first.\n\n```bash\n$ docker-compose build\n```\n\nRestart the local cluster to have your changes take effect.\n\n```bash\n$ docker-compose -p screwdriver down\n$ docker-compose -p screwdriver up\n```\n\n#### Caveats\n\nThis approach does very well with replacing complete services, and also carries some limitations:\n\n* Unable to replace individual modules with this methodology.\n\n### Local Development Instances\n\nIf you plan on making adjustments to a specific Screwdriver component, you can choose to replace a component with your development instance. This will give you a good idea on how it affects the other Screwdriver components before submitting it via Pull Request.\n\n#### General configuration\n\nOne important thing to note is that your `docker-compose.yml` will have all the components configured by I.P. address (as opposed to `localhost`). The following features will cease to work if you choose to use `localhost` instead of an I.P. address:\n\n* Builds will not start locally\n\n#### Configuring the UI\n\nYou can choose to use a local development instance of the UI.\n\nIn development mode, the UI hosts itself on port `4200` and assumes the API is served locally on `8080` by default. You would need to modify the UI's `config/environment.js` file to point to your local Screwdriver cluster, specifcally the API. This can be done by modifying the value right before the `return ENV;` statement.\n\nThe following is a snippet that highlights the change you would make in the `config/environment.js`\n\n```js\n . . .\n ENV.APP.SDAPI_HOSTNAME = 'http://11.22.33.44:8080';  // 8080 is the default. You can also change this\n return ENV;\n```\n\nThe following snippet highlights the `docker-compose.yml` values that need to be modified to use your local UI instance along with the SD-in-a-box cluster.\n\n```\nversion: '2'\nservices:\n  api:\n    . . .\n    ports:\n      - 8080:80    # UI default port for API is 8080. This can be changed according to the value you set in config/environment.js\n    environment:\n      URI: http://11.22.33.44:8080             # Tells the launcher where to communicate build updates to the API.\n      ECOSYSTEM_UI: http://11.22.33.44:4200    # Tells the API where the UI is hosted. Related to OAuth mismatching-hostname issues\n    . . .\n```\n\nPlease note that you cannot use `localhost` for the `ECOSYSTEM_UI` value if the `URI` value is set to an I.P. address. You will receive an invalid token after log-in.\n\n#### Configuring the API\n\nYou can choose to use a local development instance of the API.\n\nFurther customization can be done by setting the related environment variables. Learn more in [the API documentation](https://github.com/screwdriver-cd/screwdriver#environment)\n\n\n#### Configuring the Store\n\nYou can choose to use a localhost development instance of the Store.\n\nIn development mode, the Store hosts itself on port `80` by default. You may change this value to whichever port you desire. For the purposes of this guide, we will assume it's hosted on `8888`.\n\nThe following snippet highlights the `docker-compose.yml` values that need to be modified to use your local store instance along with the SD-in-a-box cluster.\n\n```\nversion: '2'\nservices:\n  store:\n    . . .\n    ports:\n      - 8888:80    # Port 8888 is arbitrary. You can choose another if you prefer\n    environment:\n      URI: http://11.22.33.44:9001\n      ECOSYSTEM_STORE: http://10.73.202.183:8888    # Tells the API where the store is hosted\n    . . .\n```\n",
id: 36
});

index.add({
title: "ローカルで実行",
content: "# ローカルで実行\n\nScrewdriver-in-a-boxツールを使用することで、Screwdriverをローカルで実行することができます。\n\n## SD-in-a-Box\n\nこのツールによりScrewdriverのすべてのインスタンス（UI、API、ログストア）がローカルで起動し、試すことができます。\n\n### 必要なもの\n\n- Mac OSX 10.10+\n- [Docker for Mac](https://www.docker.com/products/docker)\n- [Docker Compose 1.8.1+](https://www.docker.com/products/docker-compose)\n- Python 2.6+\n\n次のコマンドを端末で実行するとScrewdriverクラスタがローカルに起動します。\n\n```bash\n$ python <(curl https://raw.githubusercontent.com/screwdriver-cd/screwdriver/master/in-a-box.py)\n```\n\nClient IDとClient Secretを聞かれますので入力します。その後`y`と入力すればScrewdriverが起動します！\n\n![SD-in-a-box](../../cluster-management/assets/sd-in-a-box.png)\n\n## SD-in-a-Boxの設定\n\nSD-in-a-boxはScrewdriverクラスタを各開発環境で簡単に稼働させるためツールで、これを利用することでScrewdriverの機能を直接体験することができます。\n\n### カスタムDockerイメージ\n\nDockerを利用しているため、どのイメージを利用するか指定できます。SD-in-a-Box（とScrewdriver全体）としては下記のDockerイメージを使用します。\n\n- [screwdrivercd/screwdriver](https://hub.docker.com/r/screwdrivercd/screwdriver) - API。CI/CDクラスタのメインエンジン\n- [screwdrivercd/ui](https://hub.docker.com/r/screwdrivercd/ui) - Screwdriverと楽しく対話するためのUI\n- [screwdrivercd/store](https://hub.docker.com/r/screwdrivercd/store) - アーティファクトリポジトリ。ビルドログやテンプレートなどのアーティファクトに責任を持つ\n- [screwdrivercd/launcher](https://hub.docker.com/r/screwdrivercd/launcher/tags/) - ビルドを実行するワーカーコンポーネント。イメージの変更は*できません*。使用するタグの指定のみ可能です。\n\n下記は`docker-compose.yml`ファイルのスニペットです。\n\n```\nversion: '2'\nservices:\n  api:\n    image: screwdrivercd/screwdriver:stable\n    . . .\n  ui:\n    image: screwdrivercd/ui:stable\n    . . .\n  store:\n    image: screwdrivercd/store:stable\n    . . .\n```\n\nこれらを使用する代わりにローカルのDockerイメージを利用することもできます。\n\nSD-in-a-Boxを起動するには、以下のコマンドを実行してください。\n\n```bash\n$ docker-compose -p screwdriver up\n```\n\n### Volume-Mounted Source Code\n\nローカルコピーとして、コンポーネントを選択し、変更することができます。 もしあなたがサービスの更新のための開発中で、クラスタ全体にどのような影響が出るかを確認したい場合、この方法は大変効果的です\n\n変更したいコンポーネントに合わせて`docker-compose.yaml`を修正します。 例えば、以下のローカルのソース修正で、APIを変更することができます。\n\n```\nservices:\n  api:\n    # this \"build\" stanza replaces the default \"image\" setting\n    build:\n      context: ./relative/path/to/api_source\n      dockerfile: Dockerfile.local\n  ui:\n    . . .\n  store:\n    . . .\n```\n\n修正を反映させるために、docker-composeをリビルドする必要があります。\n\n```bash\n$ docker-compose build\n```\n\nローカルクラスタを再起動することで、行った修正が適用されます。\n\n```bash\n$ docker-compose -p screwdriver down\n$ docker-compose -p screwdriver up\n```\n\n#### 警告\n\nこの方法はサービス全体の変更には効果的ですが、いくつかの制限があります。\n\n- この方法では、個々のモジュールを変更することはできません。\n\n### Local Development Instances\n\nもしあなたが特定のScrewdriverのコンポーネントを修正しようとしているなら、あなたの開発環境でコンポーネントを変更することができます。これはプルリクエストを送る前に、修正が他のScrewdriverのコンポーネントにどのような影響を与えるか調べるのに良い方法になるでしょう。\n\n#### General configuration\n\n`docker-compose.yml`に記述されているコンポーネントは全てIPアドレスが設定されています(`localhost`ではなく)。 以下の機能はIPアドレスの代わりに`localhost`を使用すると停止してしまいます。\n\n- ローカルでビルドは始まらないでしょう\n\n#### UIの設定\n\nUIのローカル開発インスタンスを使うように設定することが可能です。\n\nデフォルトでUIはポートを`4200`に、APIはポートを`8080`に設定されています。UIの`config/environment.js`をローカルのScrewdriverのクラスタ、特にAPIを指すように変更する必要があるかもしれません。この変更は、`return ENV;`文の丁度一行前の値を変更することで可能です。\n\n以下のスニペットは`config/environment.js`で変更すべき部分のハイライトです。\n\n```js\n . . .\n ENV.APP.SDAPI_HOSTNAME = 'http://11.22.33.44:8080';  // 8080 is the default. You can also change this\n return ENV;\n```\n\n以下のスニペットは`docker-compose.yml`で変更すべき部分のハイライトです。ローカルのUIインスタンスを使用するために、SD-in-a-boxクラスタに合わせる必要があります。\n\n```\nversion: '2'\nservices:\n  api:\n    . . .\n    ports:\n      - 8080:80    # UI default port for API is 8080. This can be changed according to the value you set in config/environment.js\n    environment:\n      URI: http://11.22.33.44:8080             # Tells the launcher where to communicate build updates to the API.\n      ECOSYSTEM_UI: http://11.22.33.44:4200    # Tells the API where the UI is hosted. Related to OAuth mismatching-hostname issues\n    . . .\n```\n\n`URI`の値にIPアドレスを設定している場合、`localhost`を`ECOSYSTEM_UI`の値に設定することはできません。ログイン後に有効でないトークンを受け取ってしまいます。\n\n#### APIの設定\n\nAPIのローカル開発インスタンスを使うように設定することが可能です。\n\n関連する環境変数を設定することで高度な設定が可能です。詳しくは[the API documentation](https://github.com/screwdriver-cd/screwdriver#environment)をご覧ください。\n\n#### Storeの設定\n\nストアのローカル開発インスタンスを使うように設定することが可能です。\n\nデフォルトではストアのポートは`80`に設定されています。この値を自由に変更することができます。このガイドでは`8888`に変更しています。\n\n以下のスニペットは`docker-compose.yml`で変更すべき部分のハイライトです。ローカルのストアインスタンスを使用するためにSD-in-a-boxクラスタに合わせる必要があります。\n\n```\nversion: '2'\nservices:\n  store:\n    . . .\n    ports:\n      - 8888:80    # Port 8888 is arbitrary. You can choose another if you prefer\n    environment:\n      URI: http://11.22.33.44:9001\n      ECOSYSTEM_STORE: http://10.73.202.183:8888    # Tells the API where the store is hosted\n    . . .\n```\n",
id: 37
});

index.add({
title: "Secrets",
content: "# Build Secrets\nYou've got secrets to share with your jobs, but these shouldn't be shared with everyone. Screwdriver provides a mechanism to insert secrets as environment variables. Since secrets are exposed as environment variables, they are easy to use inside builds.\n\n## Security\nThe Screwdriver team takes security very seriously and encrypts all traffic between its various services. User secrets are stored encrypted in our datastore, and their values are only released to those builds that are authorized by the user.\n\nWe understand that you, the security-conscious pipeline admin, may not wish to put secrets into pull-request builds, as a malicious pull-requester could expose those secrets without your consent, but still need those secrets as part of the main build. Screwdriver provides an additional flag on secrets, `allowInPR` (default: false), that is required to be enabled for a secret to be exposed.\n\nSecrets may only be added, modified, or removed by people that are listed as admins of the Git repository associated with a given pipeline. People with \"push\" privileges may also fetch a list of secrets, but not the secret values.\n\n## Configuring a job to expose secrets\nA list of allowed secrets are added to your pipeline configuration. Secret keys may only contain A-Z and underscore characters ( \\_ ) and must start with a letter.\n\nIn the below example, an `NPM_TOKEN` secret is added to the `publish` job:\n\n```yaml\npublish:\n    steps:\n        - publish-npm: npm publish\n    secrets:\n        # Publishing to NPM\n        - NPM_TOKEN\n```\n\nYou may add secrets to any jobs you wish.\n\n### Secrets in pull-requests\nFor your own security, we don't recommend exposing secrets to pull-request builds. Pull-request jobs can be created with modified `screwdriver.yaml` files including changes to the secrets configuration.\n\nPull-requests operate essentially as copies of the `main` job. The `main` job can be set up to use a secret, and does not expose that secret to pull-requests by default.\n\n```yaml\nmain:\n    steps:\n        - my-step: maybeDoSomethingWithASecret.sh\n    secrets:\n        - MY_SECRET\n```\n\nWhen a secret is created via the UI, or API, enabling `allowInPR` will cause that secret to be available to pull-request builds, if those secrets are also configured to be exposed in the `main` job.\n\n## User Interface\nThe easiest way to create a secret for your pipeline is via the Screwdriver UI.\n![Secrets UI](../../assets/secrets.png)\n\n### Creating Secrets\nSimply enter the key and value in the inputs in the grey box, and click the add button. A checkbox is provided to allow you to enable `allowInPR`.\n\n### Updating Secrets\nA secret's original value is never delivered to the UI, but values of secrets may be updated in the UI by adding a new value in the text field next to the appropriate key name and clicking the update button.\n\n### Deleting secrets\nIndividual secrets may be removed by clicking the Delete button.\n",
id: 38
});

index.add({
title: "Secrets",
content: "# Build Secrets\n\n他には共有されず、ジョブ内でのみ共有されるsecretsを使うことができます。 Screwdriverはsecretsを環境変数として書き込む機能を提供します。secretsは環境変数として提供されるので、ビルド内で簡単に扱うことができます。\n\n## セキュリティ\n\nThe Screwdriver team takes security very seriously and encrypts all traffic between its various services. User secrets are stored encrypted in our datastore, and their values are only released to those builds that are authorized by the user.\n\nWe understand that you, the security-conscious pipeline admin, may not wish to put secrets into pull-request builds, as a malicious pull-requester could expose those secrets without your consent, but still need those secrets as part of the main build. Screwdriver provides an additional flag on secrets, `allowInPR` (default: false), that is required to be enabled for a secret to be exposed.\n\nSecrets may only be added, modified, or removed by people that are listed as admins of the Git repository associated with a given pipeline. People with \"push\" privileges may also fetch a list of secrets, but not the secret values.\n\n## Configuring a job to expose secrets\n\nA list of allowed secrets are added to your pipeline configuration. Secret keys may only contain A-Z and underscore characters ( _ ) and must start with a letter.\n\nIn the below example, an `NPM_TOKEN` secret is added to the `publish` job:\n\n```yaml\npublish:\n    steps:\n        - publish-npm: npm publish\n    secrets:\n        # Publishing to NPM\n        - NPM_TOKEN\n```\n\nYou may add secrets to any jobs you wish.\n\n### Secrets in pull-requests\n\nFor your own security, we don't recommend exposing secrets to pull-request builds. Pull-request jobs can be created with modified `screwdriver.yaml` files including changes to the secrets configuration.\n\nPull-requests operate essentially as copies of the `main` job. The `main` job can be set up to use a secret, and does not expose that secret to pull-requests by default.\n\n```yaml\nmain:\n    steps:\n        - my-step: maybeDoSomethingWithASecret.sh\n    secrets:\n        - MY_SECRET\n```\n\nWhen a secret is created via the UI, or API, enabling `allowInPR` will cause that secret to be available to pull-request builds, if those secrets are also configured to be exposed in the `main` job.\n\n## ユーザーインターフェイス\n\nパイプラインのシークレットを設定する一番簡単な方法はScrewdriverのUIを使うことです。\n![Secrets UI](../../../../assets/secrets.png)\n\n### シークレットの作成\n\nSimply enter the key and value in the inputs in the grey box, and click the add button. A checkbox is provided to allow you to enable `allowInPR`.\n\n### Updating Secrets\n\nA secret's original value is never delivered to the UI, but values of secrets may be updated in the UI by adding a new value in the text field next to the appropriate key name and clicking the update button.\n\n### Deleting secrets\n\nIndividual secrets may be removed by clicking the Delete button.\n",
id: 39
});

index.add({
title: "Support",
content: "# Support\n\n## GitHub\nScrewdriver is completely open source and can be found under the [screwdriver-cd organization](https://github.com/screwdriver-cd)\non Github. We welcome any [issues](https://github.com/screwdriver-cd/screwdriver/issues) and [pull requests](https://github.com/screwdriver-cd/screwdriver/pulls)!\nFor more information on our Github repositories and how to contribute, see the [Contributing](./contributing) page.\n\n## Slack\nWe use Slack for discussion and support. For any Screwdriver-related questions, join the `#general` channel on the\n[Screwdriver Slack team](https://screwdriver-cd.slack.com). For everything else, join the `#random` channel.\n\nTo sign up, use our [Slack inviter](http://slack.screwdriver.cd).\n\n\n## Stack Overflow\nWe monitor Stack Overflow for any posts tagged with `screwdriver-cd`. If\nthere aren't any existing questions that help with your problem, feel free to ask a new one!\n",
id: 40
});

index.add({
title: "サポート",
content: "# サポート\n\n## GitHub\n\nScrewdriverは完全なオープンソースで、GitHubの[screwdriver-cd organization](https://github.com/screwdriver-cd)以下にあります。どんな[issues](https://github.com/screwdriver-cd/screwdriver/issues)でも[pull requests](https://github.com/screwdriver-cd/screwdriver/pulls)pull requestsでも歓迎します！\nGithubのリポジトリやコントリビュート方法については [Contributing](./contributing)ページをご覧ください。\n\n## Slack\n\n議論やサポートにはSlackを利用しています（英語）。Screwdriver関連の質問があれば[Screwdriver Slack チーム](https://screwdriver-cd.slack.com)の`#general`チャンネルに参加してください。それ以外は`#random`に参加してください。\n\nサインアップするには[Slack inviter](http://slack.screwdriver.cd)を利用してください。\n\n## Stack Overflow\n\n私たちは`screwdriver-cd`\nタグが付いたStack Overflowの投稿を監視しています。問題解決に繋がる投稿がまだない場合、ぜひ新しく質問を投稿してください！\n",
id: 41
});

index.add({
title: "Templates",
content: "# Templates\n\nTemplates are snippets of predefined code that people can use to replace a job definition in a [screwdriver.yaml](./configuration). A template contains a series of predefined steps along with a selected Docker image.\n\n## Using a template\n\nTo use a template, define a `screwdriver.yaml`:\n\n```yaml\njobs:\n    main:\n        template: template_name@1.3.0\n```\n\nScrewdriver takes the template configuration and plugs it in, so that the `screwdriver.yaml` becomes:\n\n```yaml\njobs:\n    main:\n        image: node:6\n        steps:\n          - install: npm install\n          - test: npm test\n          - echo: echo $FOO\n        environment:\n           FOO: bar\n        secrets:\n          - NPM_TOKEN\n```\n\n### Wrap\nWrapping is when you add commands to run before and/or after an existing step. To wrap a step from a template, add a `pre` or `post` in front of the step name.\n\nExample:\n```yaml\njobs:\n    main:\n        template: template_name@1.3.0\n        steps:\n            - preinstall: echo pre-install\n            - postinstall: echo post-install\n```\n\nThis will run the command `echo pre-install` before the template's `install` step, and `echo post-install` after the template's `install` step.\n\n### Replace\nTo replace a step from a template, add your command with the same template's step name.\n\nExample:\n```yaml\njobs:\n    main:\n        template: template_name@1.3.0\n        steps:\n            - install: echo skip installing\n```\n\nThis will run the command `echo skip installing` for the `install` step.\n\n## Creating a template\n\n### Writing a template yaml\n\nTo create a template, create a new repo with a `sd-template.yaml` file. The file should contain a name, version, description, maintainer email, and a config with an image and steps.\n\nExample `sd-template.yaml`:\n\n```yaml\nname: template_name\nversion: '1.3'\ndescription: template for testing\nmaintainer: foo@bar.com\nconfig:\n    image: node:6\n    steps:\n        - install: npm install\n        - test: npm test\n        - echo: echo $FOO\n    environment:\n        FOO: bar\n    secrets:\n        - NPM_TOKEN\n```\n\n### Writing a screwdriver.yaml for your template repo\n\nTo validate your template, run the `template-validate` script from the `screwdriver-template-main` npm module in your `main` job to validate your template. This means the build image must have NodeJS and NPM properly installed to use it. To publish your template, run the `template-publish` script from the same module in a separate job.\n\nBy default, the file at `./sd-template.yaml` will be read. However, a user can specify a custom path using the env variable: `SD_TEMPLATE_PATH`.\n\n#### Tagging templates\nYou can optionally put a tag on specific template version. This must be done by the same pipeline that your template is created by. You will need to provide arguments to the script: name, version, and tag. The version needs to be an exact version.\n\nExample `screwdriver.yaml`:\n\n```yaml\nshared:\n    image: node:6\njobs:\n    # the main job is run in pull requests as well\n    main:\n        steps:\n            - install: npm install screwdriver-template-main\n            - validate: ./node_modules/.bin/template-validate\n        environment:\n            SD_TEMPLATE_PATH: ./path/to/template.yaml\n    publish:\n        steps:\n            - install: npm install screwdriver-template-main\n            - publish: ./node_modules/.bin/template-publish\n            - tag: ./node_modules/.bin/template-tag --name template_name --version 1.3.0 --tag stable\n        environment:\n            SD_TEMPLATE_PATH: ./path/to/template.yaml\n```\n\nCreate a Screwdriver pipeline with your template repo and start the build to validate and publish it.\n\nTo update a Screwdriver template, make changes in your SCM repository and rerun the pipeline build.\n\n## Finding templates\n\nTo figure out which templates already exist, you can make a `GET` call to the `/templates` endpoint. See the [API documentation](./api) for more information.\n",
id: 42
});

index.add({
title: "Templates",
content: "# Templates\n\nTemplates are snippets of predefined code that people can use to replace a job definition in a [screwdriver.yaml](./configuration). A template contains a series of predefined steps along with a selected Docker image.\n\n## Using a template\n\nTo use a template, define a `screwdriver.yaml`:\n\n```yaml\njobs:\n    main:\n        template: template_name@1.3.0\n```\n\nScrewdriver takes the template configuration and plugs it in, so that the `screwdriver.yaml` becomes:\n\n```yaml\njobs:\n    main:\n        image: node:6\n        steps:\n          - install: npm install\n          - test: npm test\n          - echo: echo $FOO\n        environment:\n           FOO: bar\n        secrets:\n          - NPM_TOKEN\n```\n\n### Wrap\nWrapping is when you add commands to run before and/or after an existing step. To wrap a step from a template, add a `pre` or `post` in front of the step name.\n\nExample:\n```yaml\njobs:\n    main:\n        template: template_name@1.3.0\n        steps:\n            - preinstall: echo pre-install\n            - postinstall: echo post-install\n```\n\nThis will run the command `echo pre-install` before the template's `install` step, and `echo post-install` after the template's `install` step.\n\n### Replace\nTo replace a step from a template, add your command with the same template's step name.\n\nExample:\n```yaml\njobs:\n    main:\n        template: template_name@1.3.0\n        steps:\n            - install: echo skip installing\n```\n\nThis will run the command `echo skip installing` for the `install` step.\n\n## Creating a template\n\n### Writing a template yaml\n\nTo create a template, create a new repo with a `sd-template.yaml` file. The file should contain a name, version, description, maintainer email, and a config with an image and steps.\n\nExample `sd-template.yaml`:\n\n```yaml\nname: template_name\nversion: '1.3'\ndescription: template for testing\nmaintainer: foo@bar.com\nconfig:\n    image: node:6\n    steps:\n        - install: npm install\n        - test: npm test\n        - echo: echo $FOO\n    environment:\n        FOO: bar\n    secrets:\n        - NPM_TOKEN\n```\n\n### Writing a screwdriver.yaml for your template repo\n\nTo validate your template, run the `template-validate` script from the `screwdriver-template-main` npm module in your `main` job to validate your template. This means the build image must have NodeJS and NPM properly installed to use it. To publish your template, run the `template-publish` script from the same module in a separate job.\n\nBy default, the file at `./sd-template.yaml` will be read. However, a user can specify a custom path using the env variable: `SD_TEMPLATE_PATH`.\n\nExample `screwdriver.yaml`:\n\n```yaml\nshared:\n    image: node:6\njobs:\n    # the main job is run in pull requests as well\n    main:\n        steps:\n            - install: npm install screwdriver-template-main\n            - validate: ./node_modules/.bin/template-validate\n        environment:\n            SD_TEMPLATE_PATH: ./path/to/template.yaml\n    publish:\n        steps:\n            - install: npm install screwdriver-template-main\n            - publish: ./node_modules/.bin/template-publish\n        environment:\n            SD_TEMPLATE_PATH: ./path/to/template.yaml\n```\n\nCreate a Screwdriver pipeline with your template repo and start the build to validate and publish it.\n\nTo update a Screwdriver template, make changes in your SCM repository and rerun the pipeline build.\n\n## Finding templates\n\nTo figure out which templates already exist, you can make a `GET` call to the `/templates` endpoint. See the [API documentation](./api) for more information.\n",
id: 43
});


var store = [{
  "title": null,
  "url": "/404.html",
  "summary": "\n    \n        404\n        Page not found\n    \n\n",
  "menu": "menu"
},{
  "title": "FAQ",
  "url": "/user-guide/FAQ.html",
  "summary": "Frequently Asked Questions How do I skip a build? You might want to skip a build if you’re only changing...",
  "menu": "menu"
},{
  "title": "FAQ",
  "url": "/ja/user-guide/FAQ.html",
  "summary": "Frequently Asked Questions How do I create a pipeline? To create a pipeline, click the Create icon and paste a...",
  "menu": "menu_ja"
},{
  "title": "API",
  "url": "/user-guide/api.html",
  "summary": "API Screwdriver APIs and the data models around them are documented via Swagger. This prevents out-of-date documentation, enables clients to...",
  "menu": "menu"
},{
  "title": "API",
  "url": "/ja/user-guide/api.html",
  "summary": "API ScrewdriverのAPIとデータモデルはSwaggerを使ってドキュメント化されています。ドキュメントが古くなることを防ぐため、自動生成され、人が読みやすいインタフェースになっています。 現在のAPIはVersion 4で、全てのAPIは/v4で始まります。 APIのドキュメントは以下で見ることができます api.screwdriver.cd/v4/documentation ご自身のScrewdriverで見るためには、/v4/documentationにアクセスしてください。 APIを使用する Swagger経由で使用する Swaggerのドキュメントは例とお試しのための編集可能なパラメータを含んでいます。/v4/documentationにアクセスし、APIを呼び出すためのTry it out!ボタンをお試しください。 Swagger page: Response: RESTクライアント経由で実行する PostmanのようなRESTクライアントをAPIリクエストに使用します。その際、認証トークンが必要です。認証トークンを取得するためには、/v4/auth/loginからログインし、リダイレクト先の/v4/auth/token/v4/auth/tokenからトークンをコピーしてください。詳しくは認可と認証をご覧ください。 APIリクエストの際のヘッダは以下のようになります。 Content-Type: application/json...",
  "menu": "menu_ja"
},{
  "title": "Authentication and Authorization",
  "url": "/user-guide/authentication-authorization.html",
  "summary": "Access Control To simplify access, Screwdriver uses the same security model as the Pipeline’s Git repository. Authorization For this example,...",
  "menu": "menu"
},{
  "title": "認可と認証",
  "url": "/ja/user-guide/authentication-authorization.html",
  "summary": "アクセス制御 アクセスをシンプルにするため、ScrewdriverはパイプラインのGitリポジトリと同じセキュリティモデルを採用しています。 認可 この例ではGitHub SCMプロバイダを使用します Gitリポジトリ上の各自のパーミッションレベルに応じて、リンクされているScrewdriverパイプラインへのアクセス権が設定されます。 読み取り(ゲスト) パイプライン全体の状態を表示 ビルドログの表示 書き込み(コラボレーター) ゲストが可能な操作 新しくビルドを開始 既存のビルドを停止 管理(所有者) コラボレーターが可能な操作 該当リポジトリのパイプラインの作成 既存のパイプラインの削除 secretsの作成、更新、削除 ジョブの有効化と無効化 認証...",
  "menu": "menu_ja"
},{
  "title": "Configuring the API",
  "url": "/cluster-management/configure-api.html",
  "summary": "Managing the API Packages Like the other services, the API is shipped as a Docker image with port 8080 exposed....",
  "menu": "menu"
},{
  "title": "APIの管理",
  "url": "/ja/cluster-management/configure-api.html",
  "summary": "APIの管理 パッケージ 他のサービスのように、APIは8080番ポートをexposeしたDockerイメージを提供しています。 $ docker run -d -p 9000:8080 screwdrivercd/screwdriver:stable $ open http://localhost:9000 このDockerイメージはそのバージョン(例: 1.2.3)や動的なlatest・ stableでタグ付けされています。特に理由がなければstableまたは固定のバージョンタグを利用してください。 設定 Screwdriverは最初から多くのデフォルト設定がされていますが、config/local.yaml や環境変数を使うことでデフォルト設定を上書きできます。設定できる全ての環境変数はこちらに定義されています。 認証...",
  "menu": "menu_ja"
},{
  "title": "Configuring the Store",
  "url": "/cluster-management/configure-store.html",
  "summary": "Managing the Store Packages Like the other services, the API is shipped as a Docker image with port 80 exposed....",
  "menu": "menu"
},{
  "title": "Storeの設定",
  "url": "/ja/cluster-management/configure-store.html",
  "summary": "Storeの管理 パッケージ 他のサービスと同様に、このAPIは80番ポートをexposeされたDockerイメージを提供しています。 $ docker run -d -p 7000:80 screwdrivercd/store:stable $ open http://localhost:7000 このDockerイメージはそのバージョン(例: 1.2.3) や動的なlatest・stableでタグ付けされています。特に理由がなければstableまたは固定のバージョンタグを利用してください。 設定 Screwdriverはほとんどの設定がデフォルトとして設定されていますが、これらはconfig/local.yamlや環境変数を利用して上書きすることができます。利用可能な環境変数はこちらで定義されています。 認証 APIから渡されるJWTのバリデーションについて設定します。...",
  "menu": "menu_ja"
},{
  "title": "Configuring the UI",
  "url": "/cluster-management/configure-ui.html",
  "summary": "Managing the User Interface Packages Like the other services, the User Interface is shipped as a Docker image with port...",
  "menu": "menu"
},{
  "title": "UIの設定",
  "url": "/ja/cluster-management/configure-ui.html",
  "summary": "ユーザーインターフェースの管理 パッケージ 他のサービスと同様に、80番ポートがexposeされたDockerイメージとしてユーザーインターフェースを提供しています。 $ docker run -d -p 8000:80 screwdrivercd/ui:stable $ open http://localhost:8000 このDockerイメージはそのバージョン(例: 1.2.3)や動的なlatest・stableでタグ付けされています。特に理由がなければstableまたは固定のバージョンタグを利用してください。 設定 ユーザーインターフェースにはAPIのURLという1つの設定項目しかありません。設定には環境変数ECOSYSTEM_APIを利用します。 例: $ docker...",
  "menu": "menu_ja"
},{
  "title": "Contributing",
  "url": "/about/contributing.html",
  "summary": "Contributing Thank you for considering contributing! There are many ways you can help. Bugs/Feature Requests File an issue if you...",
  "menu": "menu"
},{
  "title": "貢献する",
  "url": "/ja/about/contributing.html",
  "summary": "貢献する Contributingを考えてくれてありがとうございます！支援にはたくさんの方法があります。 Issues バグと思われるものを発見した場合は、以下を記述してIsuueを投稿してください。 どのようにすると再現しますか？ 予期した動きはどのようなものでしたか？ 実際には何が起こりましたか？ VersionやPlatformなど、その他関連のありそうなもの。 You can file all issues with Screwdriver in the screwdriver repo. We...",
  "menu": "menu_ja"
},{
  "title": "Domain Model",
  "url": "/about/appendix/domain.html",
  "summary": "Domain Model Note: Parallel, series, and matrix have not been implemented yet. Everything will run in series by default. Source...",
  "menu": "menu"
},{
  "title": "ドメインモデル",
  "url": "/ja/about/appendix/domain.html",
  "summary": "ドメインモデル ソースコード ソースコードとは、ビルドやテスト、アプリケーションのパブリッシュに必要なコードとscrewdriver.yaml を含む、指定されたSCMリポジトリとブランチのことです。 ステップ A step is a named action that needs to be performed, usually a single shell...",
  "menu": "menu_ja"
},{
  "title": "Environment Variables",
  "url": "/user-guide/environment-variables.html",
  "summary": "Environment Variables Screwdriver exports a set of environment variables that you can rely on during the course of a build....",
  "menu": "menu"
},{
  "title": "Environment Variables",
  "url": "/ja/user-guide/environment-variables.html",
  "summary": "Environment Variables Screwdriver exports a set of environment variables that you can rely on during the course of a build....",
  "menu": "menu_ja"
},{
  "title": "Execution Engines",
  "url": "/about/appendix/execution-engines.html",
  "summary": "Execution Engines A workload management system for the scheduling and running of jobs. The typical enterprise requires support for multiple...",
  "menu": "menu"
},{
  "title": "Execution Engines",
  "url": "/ja/about/appendix/execution-engines.html",
  "summary": "Execution Engines ジョブのスケジューリングと実行のためのワークロード管理システム 一般的な企業では、複数のオペレーティングシステムをサポートする必要があります。 このプロジェクトのコアは、オープンソースプロジェクトと商用クラウド製品とその能力を活用することです。 TODO：ターゲットとなるユースケースと典型的なエンタープライズに結びつける サポートされる環境 第一段階 Linuxやウェブサービスとそのバックエンドサービスの典型的なユースケース。オープンソースでのリリースにあたり、以下で説明するようにいくつかの選択肢について評価しています。 第二段階 iOSやデスクトップクライアントのためのMac OSX。将来的にWindowsもサポートするかもしれません。Mac OSXスレーブへのジョブスケジューリングのためにJenkinsがサポートされる予定です。Jenkinsは多くのOSサポートがあるためここでは便利です。 なぜJenkinsはどこにも使われないのですか？ Jenkinsは他の分野でも優れたサービスを提供していますが、アーキテクチャのスケーラビリティと全体的なパフォーマンスが制限されています。 さらに、Jenkinsクラスタの管理には、高い運用上のオーバーヘッドがあります。 Jenkinsを使用しないときのマイナス面は、既存のプラグインエコシステムにアクセスできないことです。 選択基準 Yahooの外部で利用可能であること セットアップのしやすさ...",
  "menu": "menu_ja"
},{
  "title": "What is Screwdriver?",
  "url": "/about/",
  "summary": "What is Screwdriver? A collection of services that facilitate the workflow for continuous delivery pipelines. Secure Continuous Delivery Screwdriver treats...",
  "menu": "menu"
},{
  "title": "Overall",
  "url": "/user-guide/configuration/",
  "summary": "Yaml Configuration This is an interactive guide for exploring various important properties of the screwdriver.yaml configuration for projects. You can...",
  "menu": "menu"
},{
  "title": "Overall Architecture",
  "url": "/cluster-management/",
  "summary": "Overall Architecture Screwdriver is a collection of services that facilitate the workflow for Continuous Delivery pipelines. Workflow Commit new code...",
  "menu": "menu"
},{
  "title": "Screwdriverとは",
  "url": "/ja/about/",
  "summary": "Screwdriverとは\n\n継続的デリバリーパイプラインのワークフローを簡単にするサービス群\n\n\n    \n        安全な継続的デリバリー\n        Screwdriverはあなたのビルドパイプライン上で継続的デリバリーを第一級オブジェクトとして扱います。プルリクエストからプロダクションまでの流れを簡単に定義します。\n    \n    \n        \n    \n\n\n\n    \n        \n    \n    \n        日常業務との統合\n        ScrewdriverはDevOpsの日々の習慣と繋がります。pull requestをテストし、マージされたコミットをビルドし、各自の環境にデプロイします。負荷テストやカナリアデプロイ、複数環境へのデプロイパイプラインを簡単に定義できます。\n    \n\n\n\n    \n        パイプラインをコードで記述\n        シンプルなYAMLファイルをコードに追加することでパイプラインを定義できます。パイプラインを扱う他の設定は無いため、他のコードと合わせてパイプラインの変更をレビューした上で投入できます。\n    \n    \n        \n    \n\n\n\n    \n        \n    \n    \n        あらゆる環境で動作\n        Screwdriverのアーキテクチャは挿し替え可能なコンポーネントを使用し、利用者がそれらを自身のインフラに合ったものに差し替えることができます。データストアをPostgresに変更したり、実行エンジンをJenkinsに変更することができます。また、それぞれのパイプラインに応じて実行エンジンを選択することも可能です。例えば、Go言語のビルドにはkubernetesを使用し、iOSのビルドにはJenkinsを使用する、といったことが可能です。\n    \n\n",
  "menu": "menu_ja"
},{
  "title": "全体",
  "url": "/ja/user-guide/configuration/",
  "summary": "Yaml設定 ここではscrewdriver.yamlの主要な設定についてインタラクティブに紹介します。 各プロパティ名にマウスカーソルを乗せるとそれらの説明が表示されます。 workflow: - publish - parallel: - series: - deploy-east - validate-east - series: - deploy-west - validate-west...",
  "menu": "menu_ja"
},{
  "title": "全体の構成",
  "url": "/ja/cluster-management/",
  "summary": "全体の構成 Screwdriverは継続的デリバリーパイプラインのためのワークフローを簡単にするサービス群です。 Workflow 新しいコードのコミット下記のいずれかの操作により新しいビルドが開始されます。 SCMにコードをpush SCM上で新しいpull requestを作成 pull request上に新しいコードをpush ScrewdriverのAPIやUI上で、利用者がコミットのリビルドを指示 Screwdriverへ通知 署名されたwebhooks がScrewdriverのAPIに対して変更を通知します。 ビルド実行エンジンが動作 Screwdriverに渡されたユーザーの設定やgitの情報を元に、指定されたビルド実行エンジンでビルドを開始します。 ソフトウェアのビルド 要求されたビルドコンテナ内でgitからソースコードをチェックアウトし、ユーザーの設定を元にScrewdriverのLauncherがコマンドを実行します。 アーティファクトのパブリッシュ (任意) 生成されたアーティファクトを各自のリポジトリに任意で送信できます。（RPM、Dockerイメージ、Nodeモジュールなど）...",
  "menu": "menu_ja"
},{
  "title": "ホーム",
  "url": "/ja/",
  "summary": "\n    \n    Screwdriverにようこそ\n    ドキュメントは3つの異なるセクションに分かれています\n\n\n\n    \n        クラスター管理\n        Screwdriverのクラスターを管理する方法についてはクラスター管理セクションをご覧ください。\n    \n    \n        ユーザーガイド\n        ビルドの実行にScrewdriverを利用したい場合はユーザーガイドをご覧ください。\n    \n    \n        概要\n        Screwdriverについてのその他一般的な情報については概要セクションをご覧ください。.\n    \n\n\n\n    \n        初めてScrewdriverを利用する場合、まずはドメインモデルとYAML設定を読み、Screwdriverの各種概念を理解した上でそれらがどのように繋がっているかを理解することから始めてみましょう。\n        クイックスタートの例より様々な言語のビルドを実際に試すことができます。\n    \n\n",
  "menu": "menu_ja"
},{
  "title": "Home",
  "url": "/",
  "summary": "Welcome to Screwdriver! We've split documentation into 3 distinct sections: Cluster Management To find more information about managing your own...",
  "menu": "menu"
},{
  "title": "Kubernetes",
  "url": "/cluster-management/kubernetes.html",
  "summary": "Setting Up a Screwdriver Cluster on AWS using Kubernetes We’ll go over how to set up a Screwdriver cluster on...",
  "menu": "menu"
},{
  "title": "Kubernetes",
  "url": "/ja/cluster-management/kubernetes.html",
  "summary": "Kubernetesを利用してAWS上にScrewdriverのクラスタを構築 We’ll go over how to set up a Screwdriver cluster on AWS using Kubernetes, Github, and a Postgres database....",
  "menu": "menu_ja"
},{
  "title": null,
  "url": "/js/lunr-feed.js",
  "summary": "var index = lunr(function () { this.field('title') this.field('content', {boost: 10}) this.ref('id') }); {% assign count = 0 %}{% for page...",
  "menu": ""
},{
  "title": "Metadata",
  "url": "/user-guide/configuration/metadata.html",
  "summary": "# Metadata ## What is Metadata? Metadata is a structured key/value storage of relevant information about a [build](../../about/appendix/domain#build). Metadata will...",
  "menu": "menu"
},{
  "title": "Metadata",
  "url": "/ja/user-guide/configuration/metadata.html",
  "summary": "# Metadata ## What is Metadata? Metadata is a structured key/value storage of relevant information about a [build](../../about/appendix/domain#build). Metadata will...",
  "menu": "menu_ja"
},{
  "title": "Quickstart",
  "url": "/user-guide/quickstart.html",
  "summary": "# Getting Started with Screwdriver This page will cover how to build and deploy a sample app with Screwdriver in...",
  "menu": "menu"
},{
  "title": "クイックスタート",
  "url": "/ja/user-guide/quickstart.html",
  "summary": "# Getting Started with Screwdriver このページでは、Screwdriverを利用して簡単なアプリケーションが短時間でどのようにビルド・デプロイされるか説明します。このページの例ではSCMプロバイダとしてGithubを利用します。 ## 必要なもの - Githubアカウント ## セットアップ まず最初に、サンプルリポジトリを開発環境にcloneし、そのプロジェクトディレクトリにcdします。この先の例ではgenericについて説明します。 - [generic](https://github.com/screwdriver-cd-test/quickstart-generic)* - [Golang](https://github.com/screwdriver-cd-test/quickstart-golang) - [Nodejs](https://github.com/screwdriver-cd-test/quickstart-nodejs) -...",
  "menu": "menu_ja"
},{
  "title": "Running Locally",
  "url": "/cluster-management/running-locally.html",
  "summary": "# Running Locally You can run Screwdriver locally by using our Screwdriver-in-a-box tool. ## SD-in-a-Box This handy feature will bring...",
  "menu": "menu"
},{
  "title": "ローカルで実行",
  "url": "/ja/cluster-management/running-locally.html",
  "summary": "# ローカルで実行 Screwdriver-in-a-boxツールを使用することで、Screwdriverをローカルで実行することができます。 ## SD-in-a-Box このツールによりScrewdriverのすべてのインスタンス（UI、API、ログストア）がローカルで起動し、試すことができます。 ### 必要なもの - Mac OSX 10.10+ - [Docker for Mac](https://www.docker.com/products/docker) - [Docker Compose 1.8.1+](https://www.docker.com/products/docker-compose)...",
  "menu": "menu_ja"
},{
  "title": "Secrets",
  "url": "/user-guide/configuration/secrets.html",
  "summary": "# Build Secrets You've got secrets to share with your jobs, but these shouldn't be shared with everyone. Screwdriver provides...",
  "menu": "menu"
},{
  "title": "Secrets",
  "url": "/ja/user-guide/configuration/secrets.html",
  "summary": "# Build Secrets 他には共有されず、ジョブ内でのみ共有されるsecretsを使うことができます。 Screwdriverはsecretsを環境変数として書き込む機能を提供します。secretsは環境変数として提供されるので、ビルド内で簡単に扱うことができます。 ## セキュリティ The Screwdriver team takes security very seriously and encrypts all traffic between its...",
  "menu": "menu_ja"
},{
  "title": "Support",
  "url": "/about/support.html",
  "summary": "# Support ## GitHub Screwdriver is completely open source and can be found under the [screwdriver-cd organization](https://github.com/screwdriver-cd) on Github. We...",
  "menu": "menu"
},{
  "title": "サポート",
  "url": "/ja/about/support.html",
  "summary": "# サポート ## GitHub Screwdriverは完全なオープンソースで、GitHubの[screwdriver-cd organization](https://github.com/screwdriver-cd)以下にあります。どんな[issues](https://github.com/screwdriver-cd/screwdriver/issues)でも[pull requests](https://github.com/screwdriver-cd/screwdriver/pulls)pull requestsでも歓迎します！ Githubのリポジトリやコントリビュート方法については [Contributing](./contributing)ページをご覧ください。 ## Slack 議論やサポートにはSlackを利用しています（英語）。Screwdriver関連の質問があれば[Screwdriver Slack チーム](https://screwdriver-cd.slack.com)の`#general`チャンネルに参加してください。それ以外は`#random`に参加してください。 サインアップするには[Slack inviter](http://slack.screwdriver.cd)を利用してください。 ## Stack Overflow...",
  "menu": "menu_ja"
},{
  "title": "Templates",
  "url": "/user-guide/templates.html",
  "summary": "# Templates Templates are snippets of predefined code that people can use to replace a job definition in a [screwdriver.yaml](./configuration)....",
  "menu": "menu"
},{
  "title": "Templates",
  "url": "/ja/user-guide/templates.html",
  "summary": "# Templates Templates are snippets of predefined code that people can use to replace a job definition in a [screwdriver.yaml](./configuration)....",
  "menu": "menu_ja"
}]
console.log(store[1].title);
console.log(store[1].summary);
// builds search

$(document).ready(function() {
  $('#search').on('keyup', function () {
    var resultdiv = $('#results');
    var res_count = 0;
    // Get query
    var query = $(this).val();
    // Search for it
    var result = index.search(query);
    // Show results
    resultdiv.empty();
    // Loop through, match, and add results
    for (var item in result) {
      var ref = result[item].ref;
      if(store[ref].menu == page_menu && store[ref].url != '/404.html') {
        var searchitem = '<article><h3><a href="'+store[ref].url+'">'+store[ref].title+'</a></h3><p>'+store[ref].summary+'</p></article>';
        resultdiv.append(searchitem);
        res_count = res_count + 1;
      }
    }
    if (res_count == 0) {
        var notfound = '<p>No results found</p>';
        resultdiv.append(notfound);
    }
  });
});
